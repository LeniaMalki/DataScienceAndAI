{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a31421",
   "metadata": {},
   "source": [
    "## Assignment 6 Neural Networks with Keras and TensorFlow:\n",
    "Student name | Hours spent on the tasks\n",
    "------------ | -------------\n",
    "Lenia Malki | 12\n",
    "Maële Belmont | 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff8e4c",
   "metadata": {},
   "source": [
    "Download the notebook for this assignment. The notebook will provide a basis that you can\n",
    "use to solve the exercises.\n",
    "This assignment will work with the MNIST data set. The MNIST dataset is a standard\n",
    "benchmark where small 28x28 pixel grayscale images of handwritten digits. Each image was\n",
    "manually assigned to a class label, an integer from 0 to 9, by the US Census Bureau. The task\n",
    "associated with the dataset is building a model that takes a new image (of the same size)\n",
    "and returns a class label – that is, an integer from 0 to 9.\n",
    "For this assignment, we will use the Keras framework to construct our neural networks. You\n",
    "can read more about the Keras framework here https://keras.io/. You can find information\n",
    "regarding the different layers and regularizers there. In this assignment, you can use free\n",
    "GPU leases on Google Colab or deepnote to speed up training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83ee21",
   "metadata": {},
   "source": [
    "## What to submit:\n",
    "•All Python code written.\n",
    "\n",
    "• A report that includes the figures produced and the descriptions/discussions that are requested in the questions.\n",
    "\n",
    "If you upload a zip file, please also upload any PDF files separately (so that they can be viewed more\n",
    "conveniently in Canvas).\n",
    "\n",
    "### Self-check\n",
    "Is all the required information on the front page? Have you answered all questions to the best of your ability? Anything else you can easily check? (details, terminology, arguments, clearly stated\n",
    "answers etc.?)  \n",
    "\n",
    "### Grading\n",
    "Grading will be based on a qualitative assessment of each assignment. It is important to:\n",
    "\n",
    "• Present clear arguments\n",
    "• Present the results in a pedagogical way\n",
    "• Should it be table/plot? What kind of plot? Is everything clear and easy to\n",
    "understand?\n",
    "• Show understanding of the topics\n",
    "• Give correct solutions.\n",
    "• Make sure that the code is well commented.\n",
    "• Important parts of the code should be included in the running text and the full\n",
    "code uploaded to Canvas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fdfd5b",
   "metadata": {},
   "source": [
    "### Code from DAT405_neural_networks notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5135bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f224d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters data-loading and formatting\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7756a",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(lbl_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(lbl_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d896a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model ##\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e07990",
   "metadata": {},
   "source": [
    "### 1. Preprocessing (1p)\n",
    "\n",
    "In the notebook, the data is downloaded from an external server imported into the notebook\n",
    "environment using the mnist.load_data() function call.\n",
    "Explain the data pre-processing high-lighted in the notebook.\n",
    "- explain the data split between train and test? https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5920b08",
   "metadata": {},
   "source": [
    "It is worth mentioning that the MNIST dataset consists of 70,000 28x28 grayscale pictures, representing handwritten digits from 0 to 9. (https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data#args). x_train consists of 60,000 of these pictures while x_test consists of the remaining 10,000 pictures. These pictures have a dtype of uint8, which is a data type containing a whole number from 0 up until 255. Each pixel has thus a value between 0 to 255. The training and test data sets are all divided by 255. This normalizes the data and gives us values between 0 and 1. The data has in other words been normalized. It is also worth noting that the conversion from integers to floating numbers were necessary in order to perform the division with accurate values.\n",
    "\n",
    "The lbl_train and lbl_test consist of vectors with integers between 0-9. Each vector is then converted into a binary class matrix, with 10 columns, with the use of to_categorical(). Essentially, this matrix consists of binary representations of each integer. For example, 2 would equal [0,0,1,0,0,0,0,0,0,0] (https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical). The num_classes parameter is set to 10 and represent the number of integers, 0-9) as well as the length of each vector. Finally, these two matrices are assigned to the variables y_train and y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf2593",
   "metadata": {},
   "source": [
    "### 2. Network model, training, and changing hyper-parameters. (4p)\n",
    "\n",
    "**2(A)**\n",
    "How many layers does the network in the notebook have? How many neurons does each layer\n",
    "have? What activation functions and why are these appropriate for this application? What is the\n",
    "total number of parameters for the network? Why does the input and output layers have the\n",
    "dimensions they have? <br>\n",
    "\n",
    "\n",
    "- The network in the notebook has 4 layers:\n",
    "\n",
    "n° | Layer name | Neurons in layer  \n",
    "------------ | ------------ | ------------- \n",
    "1 | flatten_3 | 784 \n",
    "2 | dense_12 | 64 \n",
    "3 | dense_13 | 64 \n",
    "4 | dense_14 | 10 \n",
    "\n",
    "- The activation functions are 'relu' and 'softmax'. These are appropriate for this application [because](https://keras.io/api/layers/activations/) ... .\n",
    "- The total number of parameters for the network is 55,050.\n",
    "- The input and output layers have these dimensions because ... ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3fa7ee",
   "metadata": {},
   "source": [
    "##### 2(B)\n",
    "What loss-function is used to train the network? What is the functional form (mathematical\n",
    "expression) of the loss function? and how should we interpret it? Why is it appropriate for the\n",
    "problem at hand?\n",
    "- Categorical cross entropy loss function\n",
    "- Functional form of the loss function: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8fb8a",
   "metadata": {},
   "source": [
    "##### 2(C)\n",
    "Train the network for 10 epochs and plot the training and validation accuracy for each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcbfe1",
   "metadata": {},
   "source": [
    "##### 2(D)\n",
    "Update model to implement a three-layer neural network where the hidden-layers has 500\n",
    "and 300 hidden units respectively. Train for 40 epochs. What is the best validation accuracy you\n",
    "can achieve? – Geoff Hinton (a co-pioneer of Deep learning) claimed this network could reach a\n",
    "validation accuracy of 0.9847 (http://yann.lecun.com/exdb/mnist/) using weight decay (L2\n",
    "regularization of weights (kernels): https://keras.io/api/layers/regularizers/). Implement weight\n",
    "decay on hidden units and train and select 5 regularization factors from 0.000001 to 0.001. Train\n",
    "3 replicates networks for each regularization factor. Plot the final validation accuracy with\n",
    "standard deviation (computed from the replicates) as a function of the regularization factor. How\n",
    "close do you get to Hintons result? – If you do not get the same results, what factors may influence this? (hint: What information is not given by Hinton on the MNIST database that may\n",
    "influence Model training) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430da424",
   "metadata": {},
   "source": [
    "### 3.  Convolutional layers. (2p)\n",
    "\n",
    "##### 3(A)\n",
    "Design a model that makes use of at least one convolutional layer – how performant a model can\n",
    "you get? -- According to the MNIST database it should be possible reach to 99% accuracy on the\n",
    "validation data. If you choose to use any layers apart from convolutional layers and layers that you\n",
    "used in previous questions, you must describe what they do. If you do not reach 99% accuracy,\n",
    "report your best performance and explain your attempts and thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ecaa4",
   "metadata": {},
   "source": [
    "##### 3(B)\n",
    "Discuss the differences and potential benefits of using convolutional layers over fully connected\n",
    "ones for the particular application?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec599416",
   "metadata": {},
   "source": [
    "### 4. Auto-Encoders for denoising (3p)\n",
    "\n",
    "##### 4(A)\n",
    "The notebook implements a simple denoising deep autoencoder model. Explain what the model\n",
    "does: use the data-preparation and model definition code to explain how the goal of the model is\n",
    "achieved. Explain the role of the loss function? Draw a diagram of the model and include it in your\n",
    "report. Train the model with the settings given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a2331",
   "metadata": {},
   "source": [
    "##### 4(B)\n",
    "Add increasing levels of noise to the test-set using the salt_and_pepper()-function (0 to 1).\n",
    "Use matplotlib to visualize a few examples (3-4) in the original, “seasoned” (noisy), and denoised\n",
    "versions (Hint: for visualization use imshow(), use the trained autoencoder to denoise the noisy\n",
    "digits). At what noise level does it become difficult to identify the digits for you? At what noise level\n",
    "does the denoising stop working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def salt_and_pepper(input, noise_level=0.5):\n",
    "    \"\"\"\n",
    "    This applies salt and pepper noise to the input tensor - randomly setting bits to 1 or 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : tensor\n",
    "        The tensor to apply salt and pepper noise to.\n",
    "    noise_level : float\n",
    "        The amount of salt and pepper noise to add.\n",
    "    Returns\n",
    "    -------\n",
    "    tensor\n",
    "        Tensor with salt and pepper noise applied.\n",
    "    \"\"\"\n",
    "    # salt and pepper noise\n",
    "    a = np.random.binomial(size=input.shape, n=1, p=(1 - noise_level))\n",
    "    b = np.random.binomial(size=input.shape, n=1, p=0.5)\n",
    "    c = (a==0) * b\n",
    "    return input * a + c\n",
    "\n",
    "\n",
    "#data preparation\n",
    "flattened_x_train = x_train.reshape(-1,784)\n",
    "flattened_x_train_seasoned = salt_and_pepper(flattened_x_train, noise_level=0.4)\n",
    "\n",
    "flattened_x_test = x_test.reshape(-1,784)\n",
    "flattened_x_test_seasoneed = salt_and_pepper(flattened_x_test, noise_level=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 96  \n",
    "\n",
    "input_image = keras.Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_image)\n",
    "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_image, decoded)\n",
    "encoder_only = keras.Model(input_image, encoded)\n",
    "\n",
    "encoded_input = keras.Input(shape=(latent_dim,))\n",
    "decoder_layer = Sequential(autoencoder.layers[-2:])\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_info_AE = autoencoder.fit(flattened_x_train_seasoned, flattened_x_train,\n",
    "                epochs=32,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(flattened_x_test_seasoneed, flattened_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69bcd1",
   "metadata": {},
   "source": [
    "##### 4(C)\n",
    "Test whether denoising improves the classification with the best performing model you obtained\n",
    "in questions 2 or 3. Plot the true-positive rate as a function of noise-level for the seasoned and\n",
    "denoised datasets – assume that the correct classification is the most likely class-label. Discuss your\n",
    "results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37ef0a",
   "metadata": {},
   "source": [
    "##### 4(D)\n",
    "Explain how you can use the decoder part of the denoising auto-encoder to generate synthetic\n",
    "“hand-written” digits? – Describe the procedure and show examples in your report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
