{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6 Neural Networks with Keras and TensorFlow:\n",
    "Student name | Hours spent on the tasks\n",
    "------------ | -------------\n",
    "Lenia Malki | 12\n",
    "Maële Belmont | 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the notebook for this assignment. The notebook will provide a basis that you can\n",
    "use to solve the exercises.\n",
    "This assignment will work with the MNIST data set. The MNIST dataset is a standard\n",
    "benchmark where small 28x28 pixel grayscale images of handwritten digits. Each image was\n",
    "manually assigned to a class label, an integer from 0 to 9, by the US Census Bureau. The task\n",
    "associated with the dataset is building a model that takes a new image (of the same size)\n",
    "and returns a class label – that is, an integer from 0 to 9.\n",
    "For this assignment, we will use the Keras framework to construct our neural networks. You\n",
    "can read more about the Keras framework here https://keras.io/. You can find information\n",
    "regarding the different layers and regularizers there. In this assignment, you can use free\n",
    "GPU leases on Google Colab or deepnote to speed up training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to submit:\n",
    "•All Python code written.\n",
    "\n",
    "• A report that includes the figures produced and the descriptions/discussions that are requested in the questions.\n",
    "\n",
    "If you upload a zip file, please also upload any PDF files separately (so that they can be viewed more\n",
    "conveniently in Canvas).\n",
    "\n",
    "### Self-check\n",
    "Is all the required information on the front page? Have you answered all questions to the best of your ability? Anything else you can easily check? (details, terminology, arguments, clearly stated\n",
    "answers etc.?)  \n",
    "\n",
    "### Grading\n",
    "Grading will be based on a qualitative assessment of each assignment. It is important to:\n",
    "\n",
    "• Present clear arguments\n",
    "• Present the results in a pedagogical way\n",
    "• Should it be table/plot? What kind of plot? Is everything clear and easy to\n",
    "understand?\n",
    "• Show understanding of the topics\n",
    "• Give correct solutions.\n",
    "• Make sure that the code is well commented.\n",
    "• Important parts of the code should be included in the running text and the full\n",
    "code uploaded to Canvas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code from DAT405_neural_networks notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import csv\n",
    "import statistics\n",
    "import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters data-loading and formatting\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(lbl_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(lbl_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing (1p)\n",
    "\n",
    "In the notebook, the data is downloaded from an external server imported into the notebook\n",
    "environment using the mnist.load_data() function call.\n",
    "Explain the data pre-processing high-lighted in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is worth mentioning that the MNIST dataset consists of 70,000 28x28 grayscale pictures, representing handwritten digits from 0 to 9. (https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data#args). x_train consists of 60,000 of these pictures while x_test consists of the remaining 10,000 pictures. These pictures have a dtype of uint8, which is a data type containing a whole number from 0 up until 255. Each pixel has thus a value between 0 to 255. The training and test data sets are all divided by 255. This normalizes the data and gives us values between 0 and 1. The data has in other words been normalized. It is also worth noting that the conversion from integers to floating numbers were necessary in order to perform the division with accurate values.\n",
    "\n",
    "- The lbl_train and lbl_test consist of vectors with integers between 0-9. Each vector is then converted into a binary class matrix, with 10 columns, with the use of to_categorical(). Essentially, this matrix consists of binary representations of each integer. For example, 2 would equal [0,0,1,0,0,0,0,0,0,0] (https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical). The num_classes parameter is set to 10 and represent the number of integers, 0-9) as well as the length of each vector. Finally, these two matrices are assigned to the variables y_train and y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Network model, training, and changing hyper-parameters. (4p)\n",
    "\n",
    "**2(A)**\n",
    "How many layers does the network in the notebook have? How many neurons does each layer\n",
    "have? What activation functions and why are these appropriate for this application? What is the\n",
    "total number of parameters for the network? Why does the input and output layers have the\n",
    "dimensions they have? <br>\n",
    "\n",
    "These information can be found in the model summary table by uncommenting line 22 '#model.summary()' of the code cell in question 2(C).\n",
    "- The network in the notebook has 4 layers:\n",
    "\n",
    "n° | Layer name | Neurons in layer  \n",
    "------------ | ------------ | ------------- \n",
    "1 | flatten_3 | 784 \n",
    "2 | dense_12 | 64 \n",
    "3 | dense_13 | 64 \n",
    "4 | dense_14 | 10 \n",
    "\n",
    "\n",
    "- The activation functions are 'relu' and 'softmax'. Since we are working with a large NN, relu is appropriate because it speeds up convergence in the training stage. Furthermore, it does not undergo the Vanishing gradient problem and is thus adequate for hidden layers in large NN. (ref.: [MLK](https://machinelearningknowledge.ai/keras-activation-layers-ultimate-guide-for-beginners/#What_is_an_Activation_Function))  The softmax activation function is appropriate because it assigns probabilities for a picture to each possible numbers [0,...,9]. The sum of the probabilities for each image is one. For example, let's say we have a picture with number 5 on it; the model might consider that it is number 5 with probability 50%, number 6 with probability 30%, number 8 with probability 11%, and number 9 with probability 9 %. Thanks to softmax, we know that the sum of the probabilities for the 10 classes [0,...,9] is one and the results are easy to interpret. (ref.: [datascience+](https://datascienceplus.com/mnist-for-machine-learning-beginners-with-softmax-regression/))      \n",
    "\n",
    "- The total number of parameters for the network is 55,050.\n",
    "- As mentioned in question 1, the MNIST dataset consists of 28x28 pictures making a total of 784 pixels per picture. These pixels, which are going to be analysed in the model, are stored in an array of size 784, explaining the dimension of the input array. The output array contains the probabilities for a picture to be each possible numbers [0,...,9]. Since there are 10 numbers, the dimension of the output is 10.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2(B)\n",
    "What loss-function is used to train the network? What is the functional form (mathematical\n",
    "expression) of the loss function? and how should we interpret it? Why is it appropriate for the\n",
    "problem at hand?\n",
    "- Categorical cross entropy loss function\n",
    "- Functional form of the loss function: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2(C)\n",
    "Train the network for 10 epochs and plot the training and validation accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1028  Test accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "## Define model ##\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "accuracies =[]\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=0, # silence the background noice\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracies.append(score)\n",
    "#model.summary()\n",
    "print('Test loss: ' + str(round(accuracies[0][0],4))+ '  Test accuracy: ' + str(round(accuracies[0][1],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for savig data to csv.file\n",
    "def saveOutput(list, name):\n",
    "    file_name = '{}.csv'.format(name)\n",
    "    \n",
    "    with open(file_name, 'w', newline='') as file:\n",
    "        if len(list[0])>=3:\n",
    "             header = ['Factor', 'Loss', 'Test']\n",
    "        else:\n",
    "            header = ['Loss', 'Test']\n",
    "        writer = csv.writer(file)   \n",
    "        writer.writerow(header)\n",
    "        for i in list:\n",
    "             writer.writerow(i)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ouput of question 2C to csv.file\n",
    "saveOutput(accuracies, '2C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for validation and accuracy of each epoch\n",
    "def plotAccuracies(history):\n",
    "    y = fit_info.history['accuracy']\n",
    "    y2 = fit_info.history['val_accuracy']\n",
    " \n",
    "    # Plot lists and show them\n",
    "    plt.plot(y, label = \"Training accuracy\")\n",
    "    plt.plot(y2, label = \"Validation accuracy\")\n",
    "\n",
    "    # Plot axes labels and show the plot\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and validation accuracy for each epoch')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    \n",
    "    x = np.arange(0, 10, 1)\n",
    "    plt.xticks(x)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotAccuracies(fit_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test accuracy of 0.7726 was obtained, with a test loss of 0.0859. This is what we achieve with the use of of only two hidden layers and 64 hidden units each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2(D)\n",
    "Update model to implement a three-layer neural network where the hidden-layers has 500\n",
    "and 300 hidden units respectively. Train for 40 epochs. What is the best validation accuracy you\n",
    "can achieve? – Geoff Hinton (a co-pioneer of Deep learning) claimed this network could reach a\n",
    "validation accuracy of 0.9847 (http://yann.lecun.com/exdb/mnist/) using weight decay (L2\n",
    "regularization of weights (kernels): https://keras.io/api/layers/regularizers/). Implement weight\n",
    "decay on hidden units and train and select 5 regularization factors from 0.000001 to 0.001. Train\n",
    "3 replicates networks for each regularization factor. Plot the final validation accuracy with\n",
    "standard deviation (computed from the replicates) as a function of the regularization factor. How\n",
    "close do you get to Hintons result? – If you do not get the same results, what factors may influence this? (hint: What information is not given by Hinton on the MNIST database that may\n",
    "influence Model training) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from csv.file\n",
    "def createDataframe(csv_file):\n",
    "    #df.columns=['Factor', 'Loss', 'Test']\n",
    "    frame =  pd.read_csv(csv_file)\n",
    "    pd.options.display.float_format = \"{:,.10f}\".format\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4000 - accuracy: 0.8892 - val_loss: 0.2126 - val_accuracy: 0.9399\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1893 - accuracy: 0.9457 - val_loss: 0.1611 - val_accuracy: 0.9530\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1387 - accuracy: 0.9605 - val_loss: 0.1215 - val_accuracy: 0.9644\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1097 - accuracy: 0.9688 - val_loss: 0.1068 - val_accuracy: 0.9678\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0895 - accuracy: 0.9742 - val_loss: 0.0927 - val_accuracy: 0.9719\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0747 - accuracy: 0.9791 - val_loss: 0.0896 - val_accuracy: 0.9719\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0771 - val_accuracy: 0.9767\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0546 - accuracy: 0.9852 - val_loss: 0.0747 - val_accuracy: 0.9766\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0473 - accuracy: 0.9871 - val_loss: 0.0733 - val_accuracy: 0.9770\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0416 - accuracy: 0.9888 - val_loss: 0.0656 - val_accuracy: 0.9794\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0676 - val_accuracy: 0.9794\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.0658 - val_accuracy: 0.9801\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.9936 - val_loss: 0.0627 - val_accuracy: 0.9806\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0239 - accuracy: 0.9948 - val_loss: 0.0650 - val_accuracy: 0.9798\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0208 - accuracy: 0.9958 - val_loss: 0.0612 - val_accuracy: 0.9809\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0609 - val_accuracy: 0.9811\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 0.0635 - val_accuracy: 0.9803\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.0683 - val_accuracy: 0.9793\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - accuracy: 0.9985 - val_loss: 0.0605 - val_accuracy: 0.9820\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.0597 - val_accuracy: 0.9824\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.0627 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.0619 - val_accuracy: 0.9812\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.0629 - val_accuracy: 0.9810\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.0624 - val_accuracy: 0.9820\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0616 - val_accuracy: 0.9820\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.0614 - val_accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0643 - val_accuracy: 0.9819\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0625 - val_accuracy: 0.9816\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0622 - val_accuracy: 0.9822\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9819\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9812\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0640 - val_accuracy: 0.9821\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9822\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9818\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9821\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9819\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9821\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9820\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.4050 - accuracy: 0.8860 - val_loss: 0.2173 - val_accuracy: 0.9393\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1929 - accuracy: 0.9451 - val_loss: 0.1578 - val_accuracy: 0.9525\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1412 - accuracy: 0.9604 - val_loss: 0.1271 - val_accuracy: 0.9615\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1110 - accuracy: 0.9680 - val_loss: 0.1089 - val_accuracy: 0.9679\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0901 - accuracy: 0.9746 - val_loss: 0.0922 - val_accuracy: 0.9719\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0755 - accuracy: 0.9789 - val_loss: 0.0852 - val_accuracy: 0.9734\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0641 - accuracy: 0.9826 - val_loss: 0.0796 - val_accuracy: 0.9753\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0550 - accuracy: 0.9846 - val_loss: 0.0763 - val_accuracy: 0.9756\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0474 - accuracy: 0.9872 - val_loss: 0.0707 - val_accuracy: 0.9792\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0417 - accuracy: 0.9889 - val_loss: 0.0656 - val_accuracy: 0.9796\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0361 - accuracy: 0.9908 - val_loss: 0.0639 - val_accuracy: 0.9811\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0314 - accuracy: 0.9924 - val_loss: 0.0656 - val_accuracy: 0.9805\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 0.0658 - val_accuracy: 0.9793\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 0.0612 - val_accuracy: 0.9804\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0211 - accuracy: 0.9956 - val_loss: 0.0609 - val_accuracy: 0.9816\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0186 - accuracy: 0.9966 - val_loss: 0.0623 - val_accuracy: 0.9807\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.0599 - val_accuracy: 0.9824\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.0597 - val_accuracy: 0.9818\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.0597 - val_accuracy: 0.9810\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.0583 - val_accuracy: 0.9816\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9989 - val_loss: 0.0614 - val_accuracy: 0.9821\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.0610 - val_accuracy: 0.9822\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.0613 - val_accuracy: 0.9815\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.0627 - val_accuracy: 0.9812\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.0626 - val_accuracy: 0.9824\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0625 - val_accuracy: 0.9818\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0632 - val_accuracy: 0.9817\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0617 - val_accuracy: 0.9822\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0621 - val_accuracy: 0.9824\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0622 - val_accuracy: 0.9829\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0627 - val_accuracy: 0.9828\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0622 - val_accuracy: 0.9827\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9823\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9824\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9818\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9824\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9820\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9829\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9827\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9826\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4037 - accuracy: 0.8885 - val_loss: 0.2130 - val_accuracy: 0.9394\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1919 - accuracy: 0.9452 - val_loss: 0.1584 - val_accuracy: 0.9530\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1402 - accuracy: 0.9600 - val_loss: 0.1243 - val_accuracy: 0.9630\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1103 - accuracy: 0.9693 - val_loss: 0.1054 - val_accuracy: 0.9683\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0906 - accuracy: 0.9741 - val_loss: 0.0951 - val_accuracy: 0.9708\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0759 - accuracy: 0.9782 - val_loss: 0.0929 - val_accuracy: 0.9719\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0644 - accuracy: 0.9821 - val_loss: 0.0825 - val_accuracy: 0.9750\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0556 - accuracy: 0.9849 - val_loss: 0.0768 - val_accuracy: 0.9765\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0485 - accuracy: 0.9867 - val_loss: 0.0723 - val_accuracy: 0.9776\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 0.0721 - val_accuracy: 0.9773\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0370 - accuracy: 0.9904 - val_loss: 0.0685 - val_accuracy: 0.9779\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0672 - val_accuracy: 0.9783\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0284 - accuracy: 0.9934 - val_loss: 0.0716 - val_accuracy: 0.9774\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0248 - accuracy: 0.9943 - val_loss: 0.0640 - val_accuracy: 0.9807\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0211 - accuracy: 0.9957 - val_loss: 0.0663 - val_accuracy: 0.9794\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.0623 - val_accuracy: 0.9808\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0167 - accuracy: 0.9970 - val_loss: 0.0629 - val_accuracy: 0.9805\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.0630 - val_accuracy: 0.9804\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0132 - accuracy: 0.9984 - val_loss: 0.0636 - val_accuracy: 0.9799\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0116 - accuracy: 0.9987 - val_loss: 0.0614 - val_accuracy: 0.9806\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.0631 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0624 - val_accuracy: 0.9811\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.0612 - val_accuracy: 0.9804\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.0621 - val_accuracy: 0.9815\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0644 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0626 - val_accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0629 - val_accuracy: 0.9814\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0625 - val_accuracy: 0.9815\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9812\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9814\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0638 - val_accuracy: 0.9818\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9812\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9812\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9818\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9817\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9814\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9812\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9820\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9816\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4147 - accuracy: 0.8886 - val_loss: 0.2301 - val_accuracy: 0.9392\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1981 - accuracy: 0.9461 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1479 - accuracy: 0.9606 - val_loss: 0.1296 - val_accuracy: 0.9639\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1179 - accuracy: 0.9691 - val_loss: 0.1143 - val_accuracy: 0.9686\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0987 - accuracy: 0.9746 - val_loss: 0.1080 - val_accuracy: 0.9697\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0840 - accuracy: 0.9789 - val_loss: 0.1016 - val_accuracy: 0.9716\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0733 - accuracy: 0.9824 - val_loss: 0.0885 - val_accuracy: 0.9756\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0639 - accuracy: 0.9852 - val_loss: 0.0925 - val_accuracy: 0.9739\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0886 - val_accuracy: 0.9769\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0509 - accuracy: 0.9891 - val_loss: 0.0810 - val_accuracy: 0.9788\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0452 - accuracy: 0.9907 - val_loss: 0.0800 - val_accuracy: 0.9781\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0410 - accuracy: 0.9922 - val_loss: 0.0775 - val_accuracy: 0.9793\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 0.0775 - val_accuracy: 0.9793\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0336 - accuracy: 0.9950 - val_loss: 0.0744 - val_accuracy: 0.9804\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0309 - accuracy: 0.9956 - val_loss: 0.0732 - val_accuracy: 0.9805\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0283 - accuracy: 0.9967 - val_loss: 0.0792 - val_accuracy: 0.9797\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0263 - accuracy: 0.9974 - val_loss: 0.0753 - val_accuracy: 0.9791\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0243 - accuracy: 0.9979 - val_loss: 0.0753 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0231 - accuracy: 0.9983 - val_loss: 0.0747 - val_accuracy: 0.9805\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0216 - accuracy: 0.9986 - val_loss: 0.0760 - val_accuracy: 0.9804\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0204 - accuracy: 0.9989 - val_loss: 0.0732 - val_accuracy: 0.9815\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0196 - accuracy: 0.9991 - val_loss: 0.0732 - val_accuracy: 0.9817\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0185 - accuracy: 0.9994 - val_loss: 0.0751 - val_accuracy: 0.9816\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0177 - accuracy: 0.9995 - val_loss: 0.0731 - val_accuracy: 0.9812\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0172 - accuracy: 0.9995 - val_loss: 0.0726 - val_accuracy: 0.9818\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0165 - accuracy: 0.9997 - val_loss: 0.0735 - val_accuracy: 0.9820\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0160 - accuracy: 0.9998 - val_loss: 0.0740 - val_accuracy: 0.9816\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0156 - accuracy: 0.9998 - val_loss: 0.0746 - val_accuracy: 0.9820\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0153 - accuracy: 0.9999 - val_loss: 0.0741 - val_accuracy: 0.9822\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0736 - val_accuracy: 0.9819\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 0.0745 - val_accuracy: 0.9821\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0145 - accuracy: 0.9999 - val_loss: 0.0752 - val_accuracy: 0.9815\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9815\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9818\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9823\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9817\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9820\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9818\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9824\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9823\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 0.4107 - accuracy: 0.8880 - val_loss: 0.2255 - val_accuracy: 0.9397\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2011 - accuracy: 0.9450 - val_loss: 0.1645 - val_accuracy: 0.9533\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1490 - accuracy: 0.9603 - val_loss: 0.1331 - val_accuracy: 0.9630\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1191 - accuracy: 0.9687 - val_loss: 0.1262 - val_accuracy: 0.9640\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0990 - accuracy: 0.9746 - val_loss: 0.1012 - val_accuracy: 0.9706\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0846 - accuracy: 0.9789 - val_loss: 0.0961 - val_accuracy: 0.9728\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0732 - accuracy: 0.9827 - val_loss: 0.0932 - val_accuracy: 0.9741\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0647 - accuracy: 0.9850 - val_loss: 0.0835 - val_accuracy: 0.9770\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0568 - accuracy: 0.9874 - val_loss: 0.0832 - val_accuracy: 0.9764\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0517 - accuracy: 0.9890 - val_loss: 0.0779 - val_accuracy: 0.9772\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0453 - accuracy: 0.9914 - val_loss: 0.0775 - val_accuracy: 0.9777\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9926 - val_loss: 0.0764 - val_accuracy: 0.9788\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0371 - accuracy: 0.9938 - val_loss: 0.0752 - val_accuracy: 0.9789\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0339 - accuracy: 0.9948 - val_loss: 0.0726 - val_accuracy: 0.9807\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0308 - accuracy: 0.9957 - val_loss: 0.0724 - val_accuracy: 0.9805\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0286 - accuracy: 0.9965 - val_loss: 0.0790 - val_accuracy: 0.9785\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0264 - accuracy: 0.9972 - val_loss: 0.0710 - val_accuracy: 0.9803\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0245 - accuracy: 0.9977 - val_loss: 0.0707 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0229 - accuracy: 0.9984 - val_loss: 0.0738 - val_accuracy: 0.9797\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0215 - accuracy: 0.9987 - val_loss: 0.0731 - val_accuracy: 0.9814\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0205 - accuracy: 0.9989 - val_loss: 0.0743 - val_accuracy: 0.9793\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0193 - accuracy: 0.9991 - val_loss: 0.0729 - val_accuracy: 0.9811\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0184 - accuracy: 0.9994 - val_loss: 0.0716 - val_accuracy: 0.9805\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0176 - accuracy: 0.9995 - val_loss: 0.0723 - val_accuracy: 0.9800\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0171 - accuracy: 0.9996 - val_loss: 0.0716 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0165 - accuracy: 0.9997 - val_loss: 0.0724 - val_accuracy: 0.9800\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0160 - accuracy: 0.9997 - val_loss: 0.0719 - val_accuracy: 0.9811\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0155 - accuracy: 0.9998 - val_loss: 0.0724 - val_accuracy: 0.9809\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0151 - accuracy: 0.9999 - val_loss: 0.0725 - val_accuracy: 0.9811\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0738 - val_accuracy: 0.9810\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 0.0744 - val_accuracy: 0.9799\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0144 - accuracy: 0.9999 - val_loss: 0.0738 - val_accuracy: 0.9815\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0142 - accuracy: 0.9999 - val_loss: 0.0735 - val_accuracy: 0.9811\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9812\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0138 - accuracy: 0.9999 - val_loss: 0.0739 - val_accuracy: 0.9813\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9812\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9806\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9817\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9810\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9810\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 5s 9ms/step - loss: 0.4129 - accuracy: 0.8876 - val_loss: 0.2292 - val_accuracy: 0.9355\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2026 - accuracy: 0.9434 - val_loss: 0.1704 - val_accuracy: 0.9495\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1502 - accuracy: 0.9596 - val_loss: 0.1371 - val_accuracy: 0.9621\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1207 - accuracy: 0.9685 - val_loss: 0.1179 - val_accuracy: 0.9656\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0999 - accuracy: 0.9742 - val_loss: 0.1056 - val_accuracy: 0.9711\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0855 - accuracy: 0.9784 - val_loss: 0.1019 - val_accuracy: 0.9712\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0740 - accuracy: 0.9818 - val_loss: 0.0955 - val_accuracy: 0.9736\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0651 - accuracy: 0.9851 - val_loss: 0.0908 - val_accuracy: 0.9752\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0582 - accuracy: 0.9872 - val_loss: 0.0841 - val_accuracy: 0.9766\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0515 - accuracy: 0.9890 - val_loss: 0.0802 - val_accuracy: 0.9786\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0460 - accuracy: 0.9908 - val_loss: 0.0738 - val_accuracy: 0.9789\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0420 - accuracy: 0.9920 - val_loss: 0.0770 - val_accuracy: 0.9785\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0380 - accuracy: 0.9932 - val_loss: 0.0777 - val_accuracy: 0.9791\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0346 - accuracy: 0.9942 - val_loss: 0.0731 - val_accuracy: 0.9804\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0315 - accuracy: 0.9954 - val_loss: 0.0731 - val_accuracy: 0.9811\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0291 - accuracy: 0.9962 - val_loss: 0.0754 - val_accuracy: 0.9797\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0268 - accuracy: 0.9970 - val_loss: 0.0898 - val_accuracy: 0.9748\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0251 - accuracy: 0.9973 - val_loss: 0.0698 - val_accuracy: 0.9813\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0233 - accuracy: 0.9983 - val_loss: 0.0715 - val_accuracy: 0.9810\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0221 - accuracy: 0.9984 - val_loss: 0.0720 - val_accuracy: 0.9807\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0207 - accuracy: 0.9989 - val_loss: 0.0730 - val_accuracy: 0.9811\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.0706 - val_accuracy: 0.9814\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0188 - accuracy: 0.9993 - val_loss: 0.0714 - val_accuracy: 0.9816\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0180 - accuracy: 0.9995 - val_loss: 0.0733 - val_accuracy: 0.9814\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0175 - accuracy: 0.9995 - val_loss: 0.0739 - val_accuracy: 0.9814\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0167 - accuracy: 0.9997 - val_loss: 0.0718 - val_accuracy: 0.9820\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0163 - accuracy: 0.9997 - val_loss: 0.0726 - val_accuracy: 0.9809\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.9998 - val_loss: 0.0722 - val_accuracy: 0.9821\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0155 - accuracy: 0.9998 - val_loss: 0.0724 - val_accuracy: 0.9814\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0151 - accuracy: 0.9998 - val_loss: 0.0732 - val_accuracy: 0.9813\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0148 - accuracy: 0.9999 - val_loss: 0.0729 - val_accuracy: 0.9823\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 0.0726 - val_accuracy: 0.9818\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0144 - accuracy: 0.9999 - val_loss: 0.0731 - val_accuracy: 0.9826\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0142 - accuracy: 0.9999 - val_loss: 0.0742 - val_accuracy: 0.9814\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9818\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9821\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9818\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9820\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9821\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9823\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4997 - accuracy: 0.8902 - val_loss: 0.3187 - val_accuracy: 0.9364\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2903 - accuracy: 0.9450 - val_loss: 0.2766 - val_accuracy: 0.9467\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2402 - accuracy: 0.9596 - val_loss: 0.2294 - val_accuracy: 0.9605\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2095 - accuracy: 0.9679 - val_loss: 0.2095 - val_accuracy: 0.9660\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1882 - accuracy: 0.9744 - val_loss: 0.1975 - val_accuracy: 0.9710\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1726 - accuracy: 0.9787 - val_loss: 0.1837 - val_accuracy: 0.9730\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1611 - accuracy: 0.9815 - val_loss: 0.1733 - val_accuracy: 0.9758\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1513 - accuracy: 0.9842 - val_loss: 0.1790 - val_accuracy: 0.9730\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1429 - accuracy: 0.9863 - val_loss: 0.1694 - val_accuracy: 0.9764\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1364 - accuracy: 0.9883 - val_loss: 0.1627 - val_accuracy: 0.9764\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1304 - accuracy: 0.9901 - val_loss: 0.1612 - val_accuracy: 0.9775\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1245 - accuracy: 0.9915 - val_loss: 0.1680 - val_accuracy: 0.9736\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1198 - accuracy: 0.9926 - val_loss: 0.1531 - val_accuracy: 0.9788\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1155 - accuracy: 0.9935 - val_loss: 0.1522 - val_accuracy: 0.9799\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1119 - accuracy: 0.9946 - val_loss: 0.1513 - val_accuracy: 0.9779\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1081 - accuracy: 0.9958 - val_loss: 0.1551 - val_accuracy: 0.9772\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1050 - accuracy: 0.9962 - val_loss: 0.1481 - val_accuracy: 0.9797\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1020 - accuracy: 0.9969 - val_loss: 0.1444 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0993 - accuracy: 0.9975 - val_loss: 0.1441 - val_accuracy: 0.9806\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0967 - accuracy: 0.9980 - val_loss: 0.1416 - val_accuracy: 0.9807\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0944 - accuracy: 0.9982 - val_loss: 0.1405 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0922 - accuracy: 0.9985 - val_loss: 0.1403 - val_accuracy: 0.9805\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0902 - accuracy: 0.9988 - val_loss: 0.1395 - val_accuracy: 0.9795\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0885 - accuracy: 0.9990 - val_loss: 0.1401 - val_accuracy: 0.9799\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0867 - accuracy: 0.9990 - val_loss: 0.1357 - val_accuracy: 0.9810\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0850 - accuracy: 0.9993 - val_loss: 0.1342 - val_accuracy: 0.9807\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0834 - accuracy: 0.9993 - val_loss: 0.1344 - val_accuracy: 0.9803\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0818 - accuracy: 0.9995 - val_loss: 0.1316 - val_accuracy: 0.9810\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0803 - accuracy: 0.9997 - val_loss: 0.1311 - val_accuracy: 0.9816\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0789 - accuracy: 0.9997 - val_loss: 0.1313 - val_accuracy: 0.9806\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0776 - accuracy: 0.9997 - val_loss: 0.1299 - val_accuracy: 0.9801\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0763 - accuracy: 0.9998 - val_loss: 0.1281 - val_accuracy: 0.9808\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0751 - accuracy: 0.9998 - val_loss: 0.1270 - val_accuracy: 0.9807\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0739 - accuracy: 0.9998 - val_loss: 0.1263 - val_accuracy: 0.9808\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0727 - accuracy: 0.9999 - val_loss: 0.1245 - val_accuracy: 0.9805\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0716 - accuracy: 0.9999 - val_loss: 0.1245 - val_accuracy: 0.9806\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0705 - accuracy: 0.9998 - val_loss: 0.1221 - val_accuracy: 0.9814\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0694 - accuracy: 0.9999 - val_loss: 0.1220 - val_accuracy: 0.9810\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0684 - accuracy: 0.9999 - val_loss: 0.1215 - val_accuracy: 0.9810\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9999 - val_loss: 0.1208 - val_accuracy: 0.9804\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4944 - accuracy: 0.8909 - val_loss: 0.3095 - val_accuracy: 0.9380\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2882 - accuracy: 0.9456 - val_loss: 0.2561 - val_accuracy: 0.9531\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2381 - accuracy: 0.9603 - val_loss: 0.2223 - val_accuracy: 0.9623\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2087 - accuracy: 0.9686 - val_loss: 0.2022 - val_accuracy: 0.9694\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1885 - accuracy: 0.9736 - val_loss: 0.1939 - val_accuracy: 0.9709\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1733 - accuracy: 0.9778 - val_loss: 0.1876 - val_accuracy: 0.9720\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1605 - accuracy: 0.9815 - val_loss: 0.1861 - val_accuracy: 0.9705\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1510 - accuracy: 0.9840 - val_loss: 0.1683 - val_accuracy: 0.9768\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1427 - accuracy: 0.9866 - val_loss: 0.1632 - val_accuracy: 0.9775\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1355 - accuracy: 0.9887 - val_loss: 0.1645 - val_accuracy: 0.9767\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1299 - accuracy: 0.9898 - val_loss: 0.1595 - val_accuracy: 0.9792\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1241 - accuracy: 0.9917 - val_loss: 0.1560 - val_accuracy: 0.9793\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1191 - accuracy: 0.9931 - val_loss: 0.1538 - val_accuracy: 0.9798\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1149 - accuracy: 0.9940 - val_loss: 0.1550 - val_accuracy: 0.9787\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1110 - accuracy: 0.9948 - val_loss: 0.1527 - val_accuracy: 0.9788\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1077 - accuracy: 0.9955 - val_loss: 0.1480 - val_accuracy: 0.9798\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1042 - accuracy: 0.9963 - val_loss: 0.1451 - val_accuracy: 0.9808\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1014 - accuracy: 0.9972 - val_loss: 0.1428 - val_accuracy: 0.9811\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0988 - accuracy: 0.9976 - val_loss: 0.1424 - val_accuracy: 0.9809\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0962 - accuracy: 0.9981 - val_loss: 0.1418 - val_accuracy: 0.9818\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0941 - accuracy: 0.9982 - val_loss: 0.1396 - val_accuracy: 0.9805\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0918 - accuracy: 0.9988 - val_loss: 0.1394 - val_accuracy: 0.9810\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0899 - accuracy: 0.9988 - val_loss: 0.1470 - val_accuracy: 0.9774\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0880 - accuracy: 0.9992 - val_loss: 0.1427 - val_accuracy: 0.9793\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0864 - accuracy: 0.9991 - val_loss: 0.1368 - val_accuracy: 0.9815\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0846 - accuracy: 0.9992 - val_loss: 0.1343 - val_accuracy: 0.9811\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0829 - accuracy: 0.9995 - val_loss: 0.1330 - val_accuracy: 0.9815\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0814 - accuracy: 0.9996 - val_loss: 0.1304 - val_accuracy: 0.9819\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0800 - accuracy: 0.9996 - val_loss: 0.1308 - val_accuracy: 0.9808\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0786 - accuracy: 0.9997 - val_loss: 0.1301 - val_accuracy: 0.9817\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0772 - accuracy: 0.9998 - val_loss: 0.1288 - val_accuracy: 0.9818\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0761 - accuracy: 0.9998 - val_loss: 0.1273 - val_accuracy: 0.9818\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0747 - accuracy: 0.9998 - val_loss: 0.1260 - val_accuracy: 0.9818\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0735 - accuracy: 0.9999 - val_loss: 0.1263 - val_accuracy: 0.9819\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0723 - accuracy: 0.9998 - val_loss: 0.1251 - val_accuracy: 0.9813\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0713 - accuracy: 0.9999 - val_loss: 0.1234 - val_accuracy: 0.9821\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0701 - accuracy: 0.9999 - val_loss: 0.1216 - val_accuracy: 0.9825\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0691 - accuracy: 0.9999 - val_loss: 0.1220 - val_accuracy: 0.9813\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0680 - accuracy: 0.9999 - val_loss: 0.1199 - val_accuracy: 0.9829\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0670 - accuracy: 0.9999 - val_loss: 0.1195 - val_accuracy: 0.9813\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5033 - accuracy: 0.8875 - val_loss: 0.3317 - val_accuracy: 0.9315\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2942 - accuracy: 0.9438 - val_loss: 0.2528 - val_accuracy: 0.9530\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2410 - accuracy: 0.9584 - val_loss: 0.2239 - val_accuracy: 0.9619\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2104 - accuracy: 0.9674 - val_loss: 0.2075 - val_accuracy: 0.9668\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1898 - accuracy: 0.9736 - val_loss: 0.1917 - val_accuracy: 0.9706\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1744 - accuracy: 0.9776 - val_loss: 0.1822 - val_accuracy: 0.9736\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1620 - accuracy: 0.9813 - val_loss: 0.1763 - val_accuracy: 0.9744\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1525 - accuracy: 0.9837 - val_loss: 0.1773 - val_accuracy: 0.9746\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1438 - accuracy: 0.9854 - val_loss: 0.1745 - val_accuracy: 0.9754\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1369 - accuracy: 0.9876 - val_loss: 0.1618 - val_accuracy: 0.9784\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1308 - accuracy: 0.9895 - val_loss: 0.1570 - val_accuracy: 0.9790\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1248 - accuracy: 0.9910 - val_loss: 0.1568 - val_accuracy: 0.9793\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1201 - accuracy: 0.9925 - val_loss: 0.1550 - val_accuracy: 0.9777\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1154 - accuracy: 0.9938 - val_loss: 0.1553 - val_accuracy: 0.9798\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1115 - accuracy: 0.9949 - val_loss: 0.1509 - val_accuracy: 0.9796\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1081 - accuracy: 0.9955 - val_loss: 0.1449 - val_accuracy: 0.9795\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1046 - accuracy: 0.9963 - val_loss: 0.1493 - val_accuracy: 0.9802\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1020 - accuracy: 0.9969 - val_loss: 0.1430 - val_accuracy: 0.9802\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0989 - accuracy: 0.9976 - val_loss: 0.1414 - val_accuracy: 0.9806\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0967 - accuracy: 0.9980 - val_loss: 0.1392 - val_accuracy: 0.9808\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0942 - accuracy: 0.9983 - val_loss: 0.1417 - val_accuracy: 0.9798\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0919 - accuracy: 0.9987 - val_loss: 0.1446 - val_accuracy: 0.9792\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0900 - accuracy: 0.9988 - val_loss: 0.1365 - val_accuracy: 0.9804\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0882 - accuracy: 0.9989 - val_loss: 0.1346 - val_accuracy: 0.9814\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0864 - accuracy: 0.9991 - val_loss: 0.1352 - val_accuracy: 0.9807\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0849 - accuracy: 0.9993 - val_loss: 0.1335 - val_accuracy: 0.9809\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0831 - accuracy: 0.9994 - val_loss: 0.1326 - val_accuracy: 0.9810\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0817 - accuracy: 0.9995 - val_loss: 0.1313 - val_accuracy: 0.9810\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0801 - accuracy: 0.9995 - val_loss: 0.1309 - val_accuracy: 0.9805\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0787 - accuracy: 0.9997 - val_loss: 0.1281 - val_accuracy: 0.9813\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0774 - accuracy: 0.9997 - val_loss: 0.1281 - val_accuracy: 0.9811\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0760 - accuracy: 0.9997 - val_loss: 0.1265 - val_accuracy: 0.9811\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0748 - accuracy: 0.9998 - val_loss: 0.1260 - val_accuracy: 0.9807\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0736 - accuracy: 0.9998 - val_loss: 0.1246 - val_accuracy: 0.9815\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0724 - accuracy: 0.9998 - val_loss: 0.1253 - val_accuracy: 0.9810\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0713 - accuracy: 0.9999 - val_loss: 0.1234 - val_accuracy: 0.9810\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0702 - accuracy: 0.9999 - val_loss: 0.1224 - val_accuracy: 0.9808\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0692 - accuracy: 0.9999 - val_loss: 0.1208 - val_accuracy: 0.9804\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0680 - accuracy: 0.9999 - val_loss: 0.1202 - val_accuracy: 0.9806\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0670 - accuracy: 0.9999 - val_loss: 0.1184 - val_accuracy: 0.9818\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5454 - accuracy: 0.8899 - val_loss: 0.3646 - val_accuracy: 0.9371\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3347 - accuracy: 0.9459 - val_loss: 0.3000 - val_accuracy: 0.9558\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2831 - accuracy: 0.9607 - val_loss: 0.2683 - val_accuracy: 0.9636\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2521 - accuracy: 0.9680 - val_loss: 0.2469 - val_accuracy: 0.9703\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2310 - accuracy: 0.9742 - val_loss: 0.2356 - val_accuracy: 0.9710\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2150 - accuracy: 0.9784 - val_loss: 0.2266 - val_accuracy: 0.9726\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2020 - accuracy: 0.9816 - val_loss: 0.2169 - val_accuracy: 0.9726\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1902 - accuracy: 0.9846 - val_loss: 0.2121 - val_accuracy: 0.9763\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1817 - accuracy: 0.9859 - val_loss: 0.2085 - val_accuracy: 0.9765\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1732 - accuracy: 0.9879 - val_loss: 0.1970 - val_accuracy: 0.9787\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1661 - accuracy: 0.9893 - val_loss: 0.1945 - val_accuracy: 0.9775\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1595 - accuracy: 0.9905 - val_loss: 0.1928 - val_accuracy: 0.9790\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1534 - accuracy: 0.9919 - val_loss: 0.1864 - val_accuracy: 0.9800\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1476 - accuracy: 0.9931 - val_loss: 0.2035 - val_accuracy: 0.9737\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1423 - accuracy: 0.9942 - val_loss: 0.1767 - val_accuracy: 0.9802\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1375 - accuracy: 0.9952 - val_loss: 0.1820 - val_accuracy: 0.9784\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1331 - accuracy: 0.9958 - val_loss: 0.1741 - val_accuracy: 0.9790\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1289 - accuracy: 0.9965 - val_loss: 0.1695 - val_accuracy: 0.9799\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1254 - accuracy: 0.9969 - val_loss: 0.1692 - val_accuracy: 0.9809\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1213 - accuracy: 0.9978 - val_loss: 0.1642 - val_accuracy: 0.9815\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1180 - accuracy: 0.9977 - val_loss: 0.1647 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1148 - accuracy: 0.9982 - val_loss: 0.1628 - val_accuracy: 0.9799\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1118 - accuracy: 0.9987 - val_loss: 0.1578 - val_accuracy: 0.9808\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1087 - accuracy: 0.9989 - val_loss: 0.1556 - val_accuracy: 0.9818\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1061 - accuracy: 0.9991 - val_loss: 0.1524 - val_accuracy: 0.9816\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1036 - accuracy: 0.9993 - val_loss: 0.1528 - val_accuracy: 0.9815\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1010 - accuracy: 0.9992 - val_loss: 0.1487 - val_accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0987 - accuracy: 0.9993 - val_loss: 0.1480 - val_accuracy: 0.9819\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0964 - accuracy: 0.9994 - val_loss: 0.1454 - val_accuracy: 0.9815\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0943 - accuracy: 0.9994 - val_loss: 0.1482 - val_accuracy: 0.9804\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0921 - accuracy: 0.9996 - val_loss: 0.1420 - val_accuracy: 0.9827\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0900 - accuracy: 0.9997 - val_loss: 0.1423 - val_accuracy: 0.9812\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0881 - accuracy: 0.9996 - val_loss: 0.1397 - val_accuracy: 0.9811\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0861 - accuracy: 0.9997 - val_loss: 0.1368 - val_accuracy: 0.9821\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - accuracy: 0.9998 - val_loss: 0.1354 - val_accuracy: 0.9819\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0825 - accuracy: 0.9998 - val_loss: 0.1325 - val_accuracy: 0.9823\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0809 - accuracy: 0.9998 - val_loss: 0.1300 - val_accuracy: 0.9818\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0791 - accuracy: 0.9998 - val_loss: 0.1296 - val_accuracy: 0.9831\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0775 - accuracy: 0.9998 - val_loss: 0.1268 - val_accuracy: 0.9821\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0759 - accuracy: 0.9999 - val_loss: 0.1258 - val_accuracy: 0.9825\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5547 - accuracy: 0.8869 - val_loss: 0.3634 - val_accuracy: 0.9376\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3372 - accuracy: 0.9454 - val_loss: 0.2994 - val_accuracy: 0.9542\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2838 - accuracy: 0.9606 - val_loss: 0.2613 - val_accuracy: 0.9661\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2523 - accuracy: 0.9686 - val_loss: 0.2564 - val_accuracy: 0.9648\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2305 - accuracy: 0.9742 - val_loss: 0.2372 - val_accuracy: 0.9702\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2123 - accuracy: 0.9790 - val_loss: 0.2230 - val_accuracy: 0.9736\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1997 - accuracy: 0.9818 - val_loss: 0.2165 - val_accuracy: 0.9743\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1888 - accuracy: 0.9847 - val_loss: 0.2062 - val_accuracy: 0.9755\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1791 - accuracy: 0.9869 - val_loss: 0.2032 - val_accuracy: 0.9764\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1708 - accuracy: 0.9888 - val_loss: 0.1948 - val_accuracy: 0.9782\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1642 - accuracy: 0.9896 - val_loss: 0.1956 - val_accuracy: 0.9774\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1574 - accuracy: 0.9911 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1515 - accuracy: 0.9922 - val_loss: 0.1874 - val_accuracy: 0.9798\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1454 - accuracy: 0.9936 - val_loss: 0.1820 - val_accuracy: 0.9790\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1407 - accuracy: 0.9948 - val_loss: 0.1788 - val_accuracy: 0.9791\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1359 - accuracy: 0.9951 - val_loss: 0.1740 - val_accuracy: 0.9800\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1316 - accuracy: 0.9960 - val_loss: 0.1745 - val_accuracy: 0.9794\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1277 - accuracy: 0.9967 - val_loss: 0.1697 - val_accuracy: 0.9804\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1238 - accuracy: 0.9974 - val_loss: 0.1678 - val_accuracy: 0.9808\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1205 - accuracy: 0.9978 - val_loss: 0.1695 - val_accuracy: 0.9796\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1169 - accuracy: 0.9980 - val_loss: 0.1617 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1139 - accuracy: 0.9984 - val_loss: 0.1587 - val_accuracy: 0.9813\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1108 - accuracy: 0.9987 - val_loss: 0.1564 - val_accuracy: 0.9811\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1080 - accuracy: 0.9987 - val_loss: 0.1557 - val_accuracy: 0.9808\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1055 - accuracy: 0.9989 - val_loss: 0.1524 - val_accuracy: 0.9815\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1027 - accuracy: 0.9993 - val_loss: 0.1518 - val_accuracy: 0.9811\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1003 - accuracy: 0.9993 - val_loss: 0.1566 - val_accuracy: 0.9791\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0979 - accuracy: 0.9995 - val_loss: 0.1461 - val_accuracy: 0.9826\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0956 - accuracy: 0.9994 - val_loss: 0.1448 - val_accuracy: 0.9812\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0935 - accuracy: 0.9995 - val_loss: 0.1432 - val_accuracy: 0.9812\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0914 - accuracy: 0.9996 - val_loss: 0.1412 - val_accuracy: 0.9817\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0893 - accuracy: 0.9995 - val_loss: 0.1402 - val_accuracy: 0.9814\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0874 - accuracy: 0.9997 - val_loss: 0.1371 - val_accuracy: 0.9823\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0855 - accuracy: 0.9997 - val_loss: 0.1370 - val_accuracy: 0.9811\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0836 - accuracy: 0.9997 - val_loss: 0.1335 - val_accuracy: 0.9820\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0819 - accuracy: 0.9998 - val_loss: 0.1320 - val_accuracy: 0.9816\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0801 - accuracy: 0.9999 - val_loss: 0.1302 - val_accuracy: 0.9823\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0784 - accuracy: 0.9998 - val_loss: 0.1286 - val_accuracy: 0.9822\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0769 - accuracy: 0.9998 - val_loss: 0.1264 - val_accuracy: 0.9818\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0753 - accuracy: 0.9998 - val_loss: 0.1256 - val_accuracy: 0.9817\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.5473 - accuracy: 0.8902 - val_loss: 0.3719 - val_accuracy: 0.9372\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3395 - accuracy: 0.9446 - val_loss: 0.3093 - val_accuracy: 0.9515\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2873 - accuracy: 0.9589 - val_loss: 0.2738 - val_accuracy: 0.9629\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2547 - accuracy: 0.9682 - val_loss: 0.2451 - val_accuracy: 0.9695\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2327 - accuracy: 0.9737 - val_loss: 0.2334 - val_accuracy: 0.9717\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2159 - accuracy: 0.9782 - val_loss: 0.2235 - val_accuracy: 0.9730\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2020 - accuracy: 0.9816 - val_loss: 0.2128 - val_accuracy: 0.9762\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1917 - accuracy: 0.9837 - val_loss: 0.2028 - val_accuracy: 0.9772\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1810 - accuracy: 0.9865 - val_loss: 0.2012 - val_accuracy: 0.9779\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1725 - accuracy: 0.9882 - val_loss: 0.1920 - val_accuracy: 0.9801\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1653 - accuracy: 0.9896 - val_loss: 0.1957 - val_accuracy: 0.9782\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1587 - accuracy: 0.9907 - val_loss: 0.1928 - val_accuracy: 0.9766\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1524 - accuracy: 0.9923 - val_loss: 0.1848 - val_accuracy: 0.9801\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1469 - accuracy: 0.9935 - val_loss: 0.1774 - val_accuracy: 0.9803\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1416 - accuracy: 0.9943 - val_loss: 0.1764 - val_accuracy: 0.9801\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1367 - accuracy: 0.9952 - val_loss: 0.1724 - val_accuracy: 0.9812\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1323 - accuracy: 0.9963 - val_loss: 0.1688 - val_accuracy: 0.9812\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1282 - accuracy: 0.9966 - val_loss: 0.1647 - val_accuracy: 0.9832\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1244 - accuracy: 0.9975 - val_loss: 0.1623 - val_accuracy: 0.9827\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1207 - accuracy: 0.9977 - val_loss: 0.1596 - val_accuracy: 0.9822\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1176 - accuracy: 0.9980 - val_loss: 0.1560 - val_accuracy: 0.9832\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1143 - accuracy: 0.9984 - val_loss: 0.1564 - val_accuracy: 0.9816\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1114 - accuracy: 0.9984 - val_loss: 0.1526 - val_accuracy: 0.9831\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1086 - accuracy: 0.9987 - val_loss: 0.1501 - val_accuracy: 0.9831\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1059 - accuracy: 0.9990 - val_loss: 0.1478 - val_accuracy: 0.9839\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1031 - accuracy: 0.9991 - val_loss: 0.1465 - val_accuracy: 0.9835\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1006 - accuracy: 0.9993 - val_loss: 0.1434 - val_accuracy: 0.9831\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0983 - accuracy: 0.9993 - val_loss: 0.1438 - val_accuracy: 0.9828\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0959 - accuracy: 0.9995 - val_loss: 0.1401 - val_accuracy: 0.9841\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0937 - accuracy: 0.9995 - val_loss: 0.1375 - val_accuracy: 0.9835\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0915 - accuracy: 0.9996 - val_loss: 0.1373 - val_accuracy: 0.9831\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0896 - accuracy: 0.9997 - val_loss: 0.1345 - val_accuracy: 0.9836\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0876 - accuracy: 0.9997 - val_loss: 0.1321 - val_accuracy: 0.9835\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0857 - accuracy: 0.9997 - val_loss: 0.1307 - val_accuracy: 0.9828\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0839 - accuracy: 0.9998 - val_loss: 0.1306 - val_accuracy: 0.9834\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0821 - accuracy: 0.9998 - val_loss: 0.1297 - val_accuracy: 0.9826\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0804 - accuracy: 0.9998 - val_loss: 0.1273 - val_accuracy: 0.9828\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0788 - accuracy: 0.9998 - val_loss: 0.1245 - val_accuracy: 0.9844\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0771 - accuracy: 0.9999 - val_loss: 0.1245 - val_accuracy: 0.9828\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0755 - accuracy: 0.9998 - val_loss: 0.1227 - val_accuracy: 0.9832\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 1.3300 - accuracy: 0.8870 - val_loss: 1.0820 - val_accuracy: 0.9345\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.9798 - accuracy: 0.9430 - val_loss: 0.8791 - val_accuracy: 0.9538\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.8126 - accuracy: 0.9577 - val_loss: 0.7458 - val_accuracy: 0.9598\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6864 - accuracy: 0.9655 - val_loss: 0.6426 - val_accuracy: 0.9636\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5860 - accuracy: 0.9712 - val_loss: 0.5541 - val_accuracy: 0.9681\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5053 - accuracy: 0.9743 - val_loss: 0.4799 - val_accuracy: 0.9700\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4377 - accuracy: 0.9768 - val_loss: 0.4220 - val_accuracy: 0.9723\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.9795 - val_loss: 0.3798 - val_accuracy: 0.9722\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3367 - accuracy: 0.9811 - val_loss: 0.3357 - val_accuracy: 0.9738\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2989 - accuracy: 0.9829 - val_loss: 0.2982 - val_accuracy: 0.9755\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2670 - accuracy: 0.9839 - val_loss: 0.2750 - val_accuracy: 0.9752\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2416 - accuracy: 0.9844 - val_loss: 0.2511 - val_accuracy: 0.9757\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2184 - accuracy: 0.9857 - val_loss: 0.2326 - val_accuracy: 0.9747\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2008 - accuracy: 0.9857 - val_loss: 0.2149 - val_accuracy: 0.9775\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1844 - accuracy: 0.9877 - val_loss: 0.1947 - val_accuracy: 0.9796\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1714 - accuracy: 0.9876 - val_loss: 0.1885 - val_accuracy: 0.9782\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.9879 - val_loss: 0.1728 - val_accuracy: 0.9807\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1504 - accuracy: 0.9887 - val_loss: 0.1659 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1424 - accuracy: 0.9888 - val_loss: 0.1621 - val_accuracy: 0.9792\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1362 - accuracy: 0.9889 - val_loss: 0.1521 - val_accuracy: 0.9803\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1297 - accuracy: 0.9895 - val_loss: 0.1469 - val_accuracy: 0.9814\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1244 - accuracy: 0.9904 - val_loss: 0.1431 - val_accuracy: 0.9807\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1205 - accuracy: 0.9901 - val_loss: 0.1423 - val_accuracy: 0.9796\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1171 - accuracy: 0.9900 - val_loss: 0.1394 - val_accuracy: 0.9797\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1133 - accuracy: 0.9906 - val_loss: 0.1383 - val_accuracy: 0.9810\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1102 - accuracy: 0.9910 - val_loss: 0.1363 - val_accuracy: 0.9806\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1081 - accuracy: 0.9910 - val_loss: 0.1319 - val_accuracy: 0.9805\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1049 - accuracy: 0.9917 - val_loss: 0.1273 - val_accuracy: 0.9823\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1033 - accuracy: 0.9921 - val_loss: 0.1288 - val_accuracy: 0.9802\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1013 - accuracy: 0.9919 - val_loss: 0.1253 - val_accuracy: 0.9815\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0999 - accuracy: 0.9922 - val_loss: 0.1311 - val_accuracy: 0.9789\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0982 - accuracy: 0.9922 - val_loss: 0.1259 - val_accuracy: 0.9786\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0965 - accuracy: 0.9931 - val_loss: 0.1242 - val_accuracy: 0.9805\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0960 - accuracy: 0.9922 - val_loss: 0.1340 - val_accuracy: 0.9755\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0949 - accuracy: 0.9928 - val_loss: 0.1197 - val_accuracy: 0.9814\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0933 - accuracy: 0.9931 - val_loss: 0.1215 - val_accuracy: 0.9808\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0928 - accuracy: 0.9928 - val_loss: 0.1221 - val_accuracy: 0.9806\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0912 - accuracy: 0.9935 - val_loss: 0.1269 - val_accuracy: 0.9800\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0904 - accuracy: 0.9933 - val_loss: 0.1185 - val_accuracy: 0.9819\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0896 - accuracy: 0.9937 - val_loss: 0.1177 - val_accuracy: 0.9813\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3258 - accuracy: 0.8879 - val_loss: 1.0707 - val_accuracy: 0.9317\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.9798 - accuracy: 0.9425 - val_loss: 0.8932 - val_accuracy: 0.9461\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.8118 - accuracy: 0.9578 - val_loss: 0.7447 - val_accuracy: 0.9614\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6855 - accuracy: 0.9656 - val_loss: 0.6400 - val_accuracy: 0.9658\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5851 - accuracy: 0.9708 - val_loss: 0.5550 - val_accuracy: 0.9662\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5037 - accuracy: 0.9746 - val_loss: 0.4809 - val_accuracy: 0.9704\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4362 - accuracy: 0.9772 - val_loss: 0.4229 - val_accuracy: 0.9719\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.9797 - val_loss: 0.3853 - val_accuracy: 0.9682\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3360 - accuracy: 0.9807 - val_loss: 0.3287 - val_accuracy: 0.9770\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2985 - accuracy: 0.9826 - val_loss: 0.2948 - val_accuracy: 0.9769\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2668 - accuracy: 0.9837 - val_loss: 0.2810 - val_accuracy: 0.9726\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2400 - accuracy: 0.9847 - val_loss: 0.2481 - val_accuracy: 0.9774\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2176 - accuracy: 0.9863 - val_loss: 0.2263 - val_accuracy: 0.9780\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1994 - accuracy: 0.9861 - val_loss: 0.2117 - val_accuracy: 0.9771\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1836 - accuracy: 0.9870 - val_loss: 0.2086 - val_accuracy: 0.9751\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1703 - accuracy: 0.9881 - val_loss: 0.1841 - val_accuracy: 0.9793\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1598 - accuracy: 0.9881 - val_loss: 0.1735 - val_accuracy: 0.9800\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1505 - accuracy: 0.9888 - val_loss: 0.1716 - val_accuracy: 0.9785\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1421 - accuracy: 0.9893 - val_loss: 0.1640 - val_accuracy: 0.9781\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1356 - accuracy: 0.9893 - val_loss: 0.1559 - val_accuracy: 0.9797\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1292 - accuracy: 0.9902 - val_loss: 0.1505 - val_accuracy: 0.9796\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1241 - accuracy: 0.9902 - val_loss: 0.1443 - val_accuracy: 0.9803\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1201 - accuracy: 0.9902 - val_loss: 0.1421 - val_accuracy: 0.9796\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1167 - accuracy: 0.9904 - val_loss: 0.1419 - val_accuracy: 0.9795\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1134 - accuracy: 0.9906 - val_loss: 0.1370 - val_accuracy: 0.9789\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1098 - accuracy: 0.9915 - val_loss: 0.1329 - val_accuracy: 0.9805\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1067 - accuracy: 0.9919 - val_loss: 0.1299 - val_accuracy: 0.9813\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1054 - accuracy: 0.9916 - val_loss: 0.1439 - val_accuracy: 0.9767\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1025 - accuracy: 0.9921 - val_loss: 0.1321 - val_accuracy: 0.9786\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1011 - accuracy: 0.9920 - val_loss: 0.1380 - val_accuracy: 0.9766\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0996 - accuracy: 0.9924 - val_loss: 0.1251 - val_accuracy: 0.9808\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0982 - accuracy: 0.9927 - val_loss: 0.1266 - val_accuracy: 0.9807\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0968 - accuracy: 0.9926 - val_loss: 0.1334 - val_accuracy: 0.9785\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0952 - accuracy: 0.9928 - val_loss: 0.1194 - val_accuracy: 0.9819\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0948 - accuracy: 0.9926 - val_loss: 0.1291 - val_accuracy: 0.9783\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0927 - accuracy: 0.9933 - val_loss: 0.1270 - val_accuracy: 0.9788\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0925 - accuracy: 0.9928 - val_loss: 0.1244 - val_accuracy: 0.9801\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0918 - accuracy: 0.9933 - val_loss: 0.1182 - val_accuracy: 0.9810\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0901 - accuracy: 0.9937 - val_loss: 0.1181 - val_accuracy: 0.9810\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0902 - accuracy: 0.9935 - val_loss: 0.1271 - val_accuracy: 0.9765\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 1.3239 - accuracy: 0.8889 - val_loss: 1.0779 - val_accuracy: 0.9344\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.9819 - accuracy: 0.9425 - val_loss: 0.8827 - val_accuracy: 0.9524\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.8141 - accuracy: 0.9575 - val_loss: 0.7388 - val_accuracy: 0.9616\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6863 - accuracy: 0.9657 - val_loss: 0.6382 - val_accuracy: 0.9652\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5861 - accuracy: 0.9707 - val_loss: 0.5519 - val_accuracy: 0.9677\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5045 - accuracy: 0.9741 - val_loss: 0.4792 - val_accuracy: 0.9713\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.4377 - accuracy: 0.9770 - val_loss: 0.4335 - val_accuracy: 0.9692\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.9790 - val_loss: 0.3883 - val_accuracy: 0.9675\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3367 - accuracy: 0.9812 - val_loss: 0.3295 - val_accuracy: 0.9751\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2992 - accuracy: 0.9825 - val_loss: 0.2985 - val_accuracy: 0.9759\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2666 - accuracy: 0.9836 - val_loss: 0.2718 - val_accuracy: 0.9759\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2405 - accuracy: 0.9848 - val_loss: 0.2482 - val_accuracy: 0.9769\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2188 - accuracy: 0.9858 - val_loss: 0.2257 - val_accuracy: 0.9782\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1998 - accuracy: 0.9866 - val_loss: 0.2073 - val_accuracy: 0.9802\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1845 - accuracy: 0.9868 - val_loss: 0.1965 - val_accuracy: 0.9799\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1711 - accuracy: 0.9878 - val_loss: 0.1879 - val_accuracy: 0.9779\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1598 - accuracy: 0.9883 - val_loss: 0.1841 - val_accuracy: 0.9766\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1500 - accuracy: 0.9886 - val_loss: 0.1718 - val_accuracy: 0.9779\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1421 - accuracy: 0.9888 - val_loss: 0.1571 - val_accuracy: 0.9811\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1359 - accuracy: 0.9893 - val_loss: 0.1665 - val_accuracy: 0.9760\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1288 - accuracy: 0.9901 - val_loss: 0.1481 - val_accuracy: 0.9808\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1243 - accuracy: 0.9899 - val_loss: 0.1548 - val_accuracy: 0.9769\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1204 - accuracy: 0.9901 - val_loss: 0.1428 - val_accuracy: 0.9800\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1159 - accuracy: 0.9904 - val_loss: 0.1405 - val_accuracy: 0.9795\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1126 - accuracy: 0.9907 - val_loss: 0.1370 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1101 - accuracy: 0.9907 - val_loss: 0.1351 - val_accuracy: 0.9809\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1072 - accuracy: 0.9916 - val_loss: 0.1412 - val_accuracy: 0.9764\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1055 - accuracy: 0.9915 - val_loss: 0.1301 - val_accuracy: 0.9806\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1033 - accuracy: 0.9916 - val_loss: 0.1336 - val_accuracy: 0.9785\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1010 - accuracy: 0.9919 - val_loss: 0.1278 - val_accuracy: 0.9806\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0998 - accuracy: 0.9922 - val_loss: 0.1244 - val_accuracy: 0.9821\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0981 - accuracy: 0.9922 - val_loss: 0.1235 - val_accuracy: 0.9820\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0970 - accuracy: 0.9923 - val_loss: 0.1204 - val_accuracy: 0.9816\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0955 - accuracy: 0.9926 - val_loss: 0.1212 - val_accuracy: 0.9820\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0950 - accuracy: 0.9924 - val_loss: 0.1214 - val_accuracy: 0.9812\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0937 - accuracy: 0.9926 - val_loss: 0.1222 - val_accuracy: 0.9805\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0929 - accuracy: 0.9929 - val_loss: 0.1322 - val_accuracy: 0.9759\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0917 - accuracy: 0.9927 - val_loss: 0.1162 - val_accuracy: 0.9824\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0907 - accuracy: 0.9930 - val_loss: 0.1184 - val_accuracy: 0.9813\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0892 - accuracy: 0.9937 - val_loss: 0.1171 - val_accuracy: 0.9814\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers as reg\n",
    "\n",
    "regFactors = [0.000001, 0.00001, 0.0001, 0.00015, 0.001]\n",
    "accuracies_2 = []\n",
    "print('Running...')\n",
    "for factor in regFactors:\n",
    "    print(\"... still running\")\n",
    "    # Train 3 replicates networks for each regularization factor\n",
    "    for replicate in range(3): # 3 replicates\n",
    "        \n",
    "        ## Define model ##\n",
    "        model = Sequential()\n",
    "\n",
    "        # These are our 4 layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500, activation = 'relu', kernel_regularizer=reg.l2(factor))) ## Hidden layer\n",
    "        model.add(Dense(300, activation = 'relu', kernel_regularizer=reg.l2(factor))) ## Hidden layer\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                       optimizer=tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "                metrics=['accuracy'],)\n",
    "\n",
    "        fit_info_2 = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=40, # Train for 40 epochs\n",
    "                   verbose=1, # Silence the background noice \n",
    "                   validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        accuracies_2.append((factor,score[0], score[1]))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ouput of question 2D to csv.file and dataframe\n",
    "saveOutput(accuracies_2, '2D')\n",
    "df_2D = createDataframe('2D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize \n",
    "means = []\n",
    "sds = []\n",
    "a = df_2D['Test']\n",
    "\n",
    "# 1.Calculate the mean of each set of replicates\n",
    "i = numpy.array([0,3,6,9,12]) # Starting indices \n",
    "j = i+2 # Stop indices\n",
    "\n",
    "for k in range(len(i)):\n",
    "    m = i[k] # Start\n",
    "    n = j[k]+1 # Stop. Indexing differrs by +1 between array and dataframe\n",
    "    \n",
    "    mean = np.mean(a[m:n]) # Calculates the mean for 3 floats \n",
    "    means.append(mean) # Save it to the list \n",
    "    \n",
    "    standard_dev = np.std(a[m:n]) # Calculates the sd for 3 floats\n",
    "    sds.append(standard_dev) # Save it to the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot final validation accuracies with standard deviations\n",
    "\n",
    "plt.xlabel(\"Reg Factor\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracies with Standard Deviations\")\n",
    "\n",
    "regFactors = np.linspace(0.000001,0.001,5) # Same as regFactors\n",
    "plt.scatter(regFactors, means)\n",
    "\n",
    "plt.errorbar(regFactors, means, sds, linestyle='--', fmt='o', markersize=4, capsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max validation accuracy:  0.9832000136375428\n",
      "Approximately 0.0015 below Hintons\n"
     ]
    }
   ],
   "source": [
    "print(\"Max validation accuracy: \", np.max(df_2D['Test']))\n",
    "k = 0.9847-np.max(df_2D['Test'])\n",
    "print('Approximately ' + str(round(k,4))+ ' below Hintons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our validation accuracy is very close to that of Hinton's though it is not quite the same. Ours is 0.15 percentage points less. It is possible that, by increasing the replications, a greater validation accuracy could be achieved. As we are dealing with standard deviation of a very small sample, namely three points per regularization factor, each data point has 1/3 influence on the standard deviation, meaning that if we were to have many outliers, the validation accuracy would be affected likewise. The chosen learning rate-epochs pairs also influences the accuracy as well as the actual values chosen for the regularization factors. In other words, there are quite a few parameters involved in the algorithm, all which can influence the final validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">INSERT COMMENT TO ABOVE ACCURACY SCORES</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Convolutional layers. (2p)\n",
    "\n",
    "##### 3(A)\n",
    "Design a model that makes use of at least one convolutional layer – how performant a model can\n",
    "you get? -- According to the MNIST database it should be possible reach to 99% accuracy on the\n",
    "validation data. If you choose to use any layers apart from convolutional layers and layers that you\n",
    "used in previous questions, you must describe what they do. If you do not reach 99% accuracy,\n",
    "report your best performance and explain your attempts and thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3(B)\n",
    "Discuss the differences and potential benefits of using convolutional layers over fully connected\n",
    "ones for the particular application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Auto-Encoders for denoising (3p)\n",
    "\n",
    "##### 4(A)\n",
    "The notebook implements a simple denoising deep autoencoder model. Explain what the model\n",
    "does: use the data-preparation and model definition code to explain how the goal of the model is\n",
    "achieved. Explain the role of the loss function? Draw a diagram of the model and include it in your\n",
    "report. Train the model with the settings given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def salt_and_pepper(input, noise_level=0.5):\n",
    "    \"\"\"\n",
    "    This applies salt and pepper noise to the input tensor - randomly setting bits to 1 or 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : tensor\n",
    "        The tensor to apply salt and pepper noise to.\n",
    "    noise_level : float\n",
    "        The amount of salt and pepper noise to add.\n",
    "    Returns\n",
    "    -------\n",
    "    tensor\n",
    "        Tensor with salt and pepper noise applied.\n",
    "    \"\"\"\n",
    "    # salt and pepper noise\n",
    "    a = np.random.binomial(size=input.shape, n=1, p=(1 - noise_level))\n",
    "    b = np.random.binomial(size=input.shape, n=1, p=0.5)\n",
    "    c = (a==0) * b\n",
    "    return input * a + c\n",
    "\n",
    "\n",
    "#data preparation\n",
    "flattened_x_train = x_train.reshape(-1,784)\n",
    "flattened_x_train_seasoned = salt_and_pepper(flattened_x_train, noise_level=0.4)\n",
    "\n",
    "flattened_x_test = x_test.reshape(-1,784)\n",
    "flattened_x_test_seasoneed = salt_and_pepper(flattened_x_test, noise_level=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 96  \n",
    "\n",
    "input_image = keras.Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_image)\n",
    "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_image, decoded)\n",
    "encoder_only = keras.Model(input_image, encoded)\n",
    "\n",
    "encoded_input = keras.Input(shape=(latent_dim,))\n",
    "decoder_layer = Sequential(autoencoder.layers[-2:])\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_info_AE = autoencoder.fit(flattened_x_train_seasoned, flattened_x_train,\n",
    "                epochs=32,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(flattened_x_test_seasoneed, flattened_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4(B)\n",
    "Add increasing levels of noise to the test-set using the salt_and_pepper()-function (0 to 1).\n",
    "Use matplotlib to visualize a few examples (3-4) in the original, “seasoned” (noisy), and denoised\n",
    "versions (Hint: for visualization use imshow(), use the trained autoencoder to denoise the noisy\n",
    "digits). At what noise level does it become difficult to identify the digits for you? At what noise level\n",
    "does the denoising stop working?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4(C)\n",
    "Test whether denoising improves the classification with the best performing model you obtained\n",
    "in questions 2 or 3. Plot the true-positive rate as a function of noise-level for the seasoned and\n",
    "denoised datasets – assume that the correct classification is the most likely class-label. Discuss your\n",
    "results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4(D)\n",
    "Explain how you can use the decoder part of the denoising auto-encoder to generate synthetic\n",
    "“hand-written” digits? – Describe the procedure and show examples in your report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
