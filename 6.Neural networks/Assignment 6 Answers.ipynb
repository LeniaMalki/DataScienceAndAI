{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a31421",
   "metadata": {},
   "source": [
    "## Assignment 6 Neural Networks with Keras and TensorFlow:\n",
    "Student name | Hours spent on the tasks\n",
    "------------ | -------------\n",
    "Lenia Malki | 12\n",
    "Maële Belmont | 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff8e4c",
   "metadata": {},
   "source": [
    "Download the notebook for this assignment. The notebook will provide a basis that you can\n",
    "use to solve the exercises.\n",
    "This assignment will work with the MNIST data set. The MNIST dataset is a standard\n",
    "benchmark where small 28x28 pixel grayscale images of handwritten digits. Each image was\n",
    "manually assigned to a class label, an integer from 0 to 9, by the US Census Bureau. The task\n",
    "associated with the dataset is building a model that takes a new image (of the same size)\n",
    "and returns a class label – that is, an integer from 0 to 9.\n",
    "For this assignment, we will use the Keras framework to construct our neural networks. You\n",
    "can read more about the Keras framework here https://keras.io/. You can find information\n",
    "regarding the different layers and regularizers there. In this assignment, you can use free\n",
    "GPU leases on Google Colab or deepnote to speed up training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83ee21",
   "metadata": {},
   "source": [
    "## What to submit:\n",
    "•All Python code written.\n",
    "\n",
    "• A report that includes the figures produced and the descriptions/discussions that are requested in the questions.\n",
    "\n",
    "If you upload a zip file, please also upload any PDF files separately (so that they can be viewed more\n",
    "conveniently in Canvas).\n",
    "\n",
    "### Self-check\n",
    "Is all the required information on the front page? Have you answered all questions to the best of your ability? Anything else you can easily check? (details, terminology, arguments, clearly stated\n",
    "answers etc.?)  \n",
    "\n",
    "### Grading\n",
    "Grading will be based on a qualitative assessment of each assignment. It is important to:\n",
    "\n",
    "• Present clear arguments\n",
    "• Present the results in a pedagogical way\n",
    "• Should it be table/plot? What kind of plot? Is everything clear and easy to\n",
    "understand?\n",
    "• Show understanding of the topics\n",
    "• Give correct solutions.\n",
    "• Make sure that the code is well commented.\n",
    "• Important parts of the code should be included in the running text and the full\n",
    "code uploaded to Canvas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fdfd5b",
   "metadata": {},
   "source": [
    "### Code from DAT405_neural_networks notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5135bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import csv\n",
    "import statistics\n",
    "import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f224d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters data-loading and formatting\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7756a",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a449ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(lbl_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(lbl_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e07990",
   "metadata": {},
   "source": [
    "### 1. Preprocessing (1p)\n",
    "\n",
    "In the notebook, the data is downloaded from an external server imported into the notebook\n",
    "environment using the mnist.load_data() function call.\n",
    "Explain the data pre-processing high-lighted in the notebook.\n",
    "- explain the data split between train and test? https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfbaab2",
   "metadata": {},
   "source": [
    "It is worth mentioning that the MNIST dataset consists of 70,000 28x28 grayscale pictures, representing handwritten digits from 0 to 9. (https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data#args). x_train consists of 60,000 of these pictures while x_test consists of the remaining 10,000 pictures. These pictures have a dtype of uint8, which is a data type containing a whole number from 0 up until 255. Each pixel has thus a value between 0 to 255. The training and test data sets are all divided by 255. This normalizes the data and gives us values between 0 and 1. The data has in other words been normalized. It is also worth noting that the conversion from integers to floating numbers were necessary in order to perform the division with accurate values.\n",
    "\n",
    "The lbl_train and lbl_test consist of vectors with integers between 0-9. Each vector is then converted into a binary class matrix, with 10 columns, with the use of to_categorical(). Essentially, this matrix consists of binary representations of each integer. For example, 2 would equal [0,0,1,0,0,0,0,0,0,0] (https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical). The num_classes parameter is set to 10 and represent the number of integers, 0-9) as well as the length of each vector. Finally, these two matrices are assigned to the variables y_train and y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf2593",
   "metadata": {},
   "source": [
    "### 2. Network model, training, and changing hyper-parameters. (4p)\n",
    "\n",
    "**2(A)**\n",
    "How many layers does the network in the notebook have? How many neurons does each layer\n",
    "have? What activation functions and why are these appropriate for this application? What is the\n",
    "total number of parameters for the network? Why does the input and output layers have the\n",
    "dimensions they have? <br>\n",
    "\n",
    "\n",
    "- The network in the notebook has 4 layers:\n",
    "\n",
    "n° | Layer name | Neurons in layer  \n",
    "------------ | ------------ | ------------- \n",
    "1 | flatten_3 | 784 \n",
    "2 | dense_12 | 64 \n",
    "3 | dense_13 | 64 \n",
    "4 | dense_14 | 10 \n",
    "\n",
    "- The activation functions are 'relu' and 'softmax'. These are appropriate for this application [because](https://keras.io/api/layers/activations/) ... .\n",
    "- The total number of parameters for the network is 55,050.\n",
    "- The input and output layers have these dimensions because ... ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9ebb7",
   "metadata": {},
   "source": [
    "##### 2(B)\n",
    "What loss-function is used to train the network? What is the functional form (mathematical\n",
    "expression) of the loss function? and how should we interpret it? Why is it appropriate for the\n",
    "problem at hand?\n",
    "- Categorical cross entropy loss function\n",
    "- Functional form of the loss function: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e9505",
   "metadata": {},
   "source": [
    "##### 2(C)\n",
    "Train the network for 10 epochs and plot the training and validation accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d896a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0859  Test accuracy: 0.9726\n"
     ]
    }
   ],
   "source": [
    "## Define model ##\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "accuracies =[]\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=0, # silence the background noice\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracies.append(score)\n",
    "#model.summary()\n",
    "print('Test loss: ' + str(round(accuracies[0][0],4))+ '  Test accuracy: ' + str(round(accuracies[0][1],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440aefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for savig data to csv.file\n",
    "def saveOutput(list, name):\n",
    "    file_name = '{}.csv'.format(name)\n",
    "    \n",
    "    with open(file_name, 'w', newline='') as file:\n",
    "        if len(list[0])>=3:\n",
    "             header = ['Factor', 'Loss', 'Test']\n",
    "        else:\n",
    "            header = ['Loss', 'Test']\n",
    "        writer = csv.writer(file)   \n",
    "        writer.writerow(header)\n",
    "        for i in list:\n",
    "             writer.writerow(i)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cb3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ouput of question 2C to csv.file\n",
    "saveOutput(accuracies, '2C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0620d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for validation and accuracy of each epoch\n",
    "def plotAccuracies(history):\n",
    "    y = fit_info.history['accuracy']\n",
    "    y2 = fit_info.history['val_accuracy']\n",
    " \n",
    "    # Plot lists and show them\n",
    "    plt.plot(y, label = \"Training accuracy\")\n",
    "    plt.plot(y2, label = \"Validation accuracy\")\n",
    "\n",
    "    # Plot axes labels and show the plot\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and validation accuracy for each epoch')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    \n",
    "    x = np.arange(0, 10, 1)\n",
    "    plt.xticks(x)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5c4916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotAccuracies(fit_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91904888",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">INSERT COMMENT TO FIGURE OF 2C and accuracy score</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d94f4",
   "metadata": {},
   "source": [
    "##### 2(D)\n",
    "Update model to implement a three-layer neural network where the hidden-layers has 500\n",
    "and 300 hidden units respectively. Train for 40 epochs. What is the best validation accuracy you\n",
    "can achieve? – Geoff Hinton (a co-pioneer of Deep learning) claimed this network could reach a\n",
    "validation accuracy of 0.9847 (http://yann.lecun.com/exdb/mnist/) using weight decay (L2\n",
    "regularization of weights (kernels): https://keras.io/api/layers/regularizers/). Implement weight\n",
    "decay on hidden units and train and select 5 regularization factors from 0.000001 to 0.001. Train\n",
    "3 replicates networks for each regularization factor. Plot the final validation accuracy with\n",
    "standard deviation (computed from the replicates) as a function of the regularization factor. How\n",
    "close do you get to Hintons result? – If you do not get the same results, what factors may influence this? (hint: What information is not given by Hinton on the MNIST database that may\n",
    "influence Model training) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed6d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from csv.file\n",
    "def createDataframe(csv_file):\n",
    "    #df.columns=['Factor', 'Loss', 'Test']\n",
    "    frame =  pd.read_csv(csv_file)\n",
    "    pd.options.display.float_format = \"{:,.10f}\".format\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97a0a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4000 - accuracy: 0.8892 - val_loss: 0.2126 - val_accuracy: 0.9399\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1893 - accuracy: 0.9457 - val_loss: 0.1611 - val_accuracy: 0.9530\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1387 - accuracy: 0.9605 - val_loss: 0.1215 - val_accuracy: 0.9644\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1097 - accuracy: 0.9688 - val_loss: 0.1068 - val_accuracy: 0.9678\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0895 - accuracy: 0.9742 - val_loss: 0.0927 - val_accuracy: 0.9719\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0747 - accuracy: 0.9791 - val_loss: 0.0896 - val_accuracy: 0.9719\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0771 - val_accuracy: 0.9767\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0546 - accuracy: 0.9852 - val_loss: 0.0747 - val_accuracy: 0.9766\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0473 - accuracy: 0.9871 - val_loss: 0.0733 - val_accuracy: 0.9770\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0416 - accuracy: 0.9888 - val_loss: 0.0656 - val_accuracy: 0.9794\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0676 - val_accuracy: 0.9794\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.0658 - val_accuracy: 0.9801\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.9936 - val_loss: 0.0627 - val_accuracy: 0.9806\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0239 - accuracy: 0.9948 - val_loss: 0.0650 - val_accuracy: 0.9798\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0208 - accuracy: 0.9958 - val_loss: 0.0612 - val_accuracy: 0.9809\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0609 - val_accuracy: 0.9811\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 0.0635 - val_accuracy: 0.9803\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.0683 - val_accuracy: 0.9793\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - accuracy: 0.9985 - val_loss: 0.0605 - val_accuracy: 0.9820\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.0597 - val_accuracy: 0.9824\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.0627 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.0619 - val_accuracy: 0.9812\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.0629 - val_accuracy: 0.9810\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.0624 - val_accuracy: 0.9820\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0616 - val_accuracy: 0.9820\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.0614 - val_accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0643 - val_accuracy: 0.9819\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0625 - val_accuracy: 0.9816\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0622 - val_accuracy: 0.9822\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9819\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9812\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0640 - val_accuracy: 0.9821\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9822\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9818\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9821\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9819\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9821\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9820\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.4050 - accuracy: 0.8860 - val_loss: 0.2173 - val_accuracy: 0.9393\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1929 - accuracy: 0.9451 - val_loss: 0.1578 - val_accuracy: 0.9525\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1412 - accuracy: 0.9604 - val_loss: 0.1271 - val_accuracy: 0.9615\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1110 - accuracy: 0.9680 - val_loss: 0.1089 - val_accuracy: 0.9679\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0901 - accuracy: 0.9746 - val_loss: 0.0922 - val_accuracy: 0.9719\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0755 - accuracy: 0.9789 - val_loss: 0.0852 - val_accuracy: 0.9734\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0641 - accuracy: 0.9826 - val_loss: 0.0796 - val_accuracy: 0.9753\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0550 - accuracy: 0.9846 - val_loss: 0.0763 - val_accuracy: 0.9756\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0474 - accuracy: 0.9872 - val_loss: 0.0707 - val_accuracy: 0.9792\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0417 - accuracy: 0.9889 - val_loss: 0.0656 - val_accuracy: 0.9796\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0361 - accuracy: 0.9908 - val_loss: 0.0639 - val_accuracy: 0.9811\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0314 - accuracy: 0.9924 - val_loss: 0.0656 - val_accuracy: 0.9805\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 0.0658 - val_accuracy: 0.9793\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 0.0612 - val_accuracy: 0.9804\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0211 - accuracy: 0.9956 - val_loss: 0.0609 - val_accuracy: 0.9816\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0186 - accuracy: 0.9966 - val_loss: 0.0623 - val_accuracy: 0.9807\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.0599 - val_accuracy: 0.9824\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.0597 - val_accuracy: 0.9818\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.0597 - val_accuracy: 0.9810\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.0583 - val_accuracy: 0.9816\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9989 - val_loss: 0.0614 - val_accuracy: 0.9821\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.0610 - val_accuracy: 0.9822\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.0613 - val_accuracy: 0.9815\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.0627 - val_accuracy: 0.9812\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.0626 - val_accuracy: 0.9824\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0625 - val_accuracy: 0.9818\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0632 - val_accuracy: 0.9817\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0617 - val_accuracy: 0.9822\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0621 - val_accuracy: 0.9824\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0622 - val_accuracy: 0.9829\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0627 - val_accuracy: 0.9828\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0622 - val_accuracy: 0.9827\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9823\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9824\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9818\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9824\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9820\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9829\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9827\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9826\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4037 - accuracy: 0.8885 - val_loss: 0.2130 - val_accuracy: 0.9394\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1919 - accuracy: 0.9452 - val_loss: 0.1584 - val_accuracy: 0.9530\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1402 - accuracy: 0.9600 - val_loss: 0.1243 - val_accuracy: 0.9630\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1103 - accuracy: 0.9693 - val_loss: 0.1054 - val_accuracy: 0.9683\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0906 - accuracy: 0.9741 - val_loss: 0.0951 - val_accuracy: 0.9708\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0759 - accuracy: 0.9782 - val_loss: 0.0929 - val_accuracy: 0.9719\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0644 - accuracy: 0.9821 - val_loss: 0.0825 - val_accuracy: 0.9750\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0556 - accuracy: 0.9849 - val_loss: 0.0768 - val_accuracy: 0.9765\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0485 - accuracy: 0.9867 - val_loss: 0.0723 - val_accuracy: 0.9776\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 0.0721 - val_accuracy: 0.9773\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0370 - accuracy: 0.9904 - val_loss: 0.0685 - val_accuracy: 0.9779\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0672 - val_accuracy: 0.9783\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0284 - accuracy: 0.9934 - val_loss: 0.0716 - val_accuracy: 0.9774\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0248 - accuracy: 0.9943 - val_loss: 0.0640 - val_accuracy: 0.9807\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0211 - accuracy: 0.9957 - val_loss: 0.0663 - val_accuracy: 0.9794\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.0623 - val_accuracy: 0.9808\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0167 - accuracy: 0.9970 - val_loss: 0.0629 - val_accuracy: 0.9805\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.0630 - val_accuracy: 0.9804\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0132 - accuracy: 0.9984 - val_loss: 0.0636 - val_accuracy: 0.9799\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0116 - accuracy: 0.9987 - val_loss: 0.0614 - val_accuracy: 0.9806\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.0631 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0624 - val_accuracy: 0.9811\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.0612 - val_accuracy: 0.9804\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.0621 - val_accuracy: 0.9815\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0644 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0626 - val_accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0629 - val_accuracy: 0.9814\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0625 - val_accuracy: 0.9815\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9812\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9814\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0638 - val_accuracy: 0.9818\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9812\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9812\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9818\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9817\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9814\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9812\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9820\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9816\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4147 - accuracy: 0.8886 - val_loss: 0.2301 - val_accuracy: 0.9392\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1981 - accuracy: 0.9461 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1479 - accuracy: 0.9606 - val_loss: 0.1296 - val_accuracy: 0.9639\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1179 - accuracy: 0.9691 - val_loss: 0.1143 - val_accuracy: 0.9686\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0987 - accuracy: 0.9746 - val_loss: 0.1080 - val_accuracy: 0.9697\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0840 - accuracy: 0.9789 - val_loss: 0.1016 - val_accuracy: 0.9716\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0733 - accuracy: 0.9824 - val_loss: 0.0885 - val_accuracy: 0.9756\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0639 - accuracy: 0.9852 - val_loss: 0.0925 - val_accuracy: 0.9739\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0886 - val_accuracy: 0.9769\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0509 - accuracy: 0.9891 - val_loss: 0.0810 - val_accuracy: 0.9788\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0452 - accuracy: 0.9907 - val_loss: 0.0800 - val_accuracy: 0.9781\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0410 - accuracy: 0.9922 - val_loss: 0.0775 - val_accuracy: 0.9793\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 0.0775 - val_accuracy: 0.9793\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0336 - accuracy: 0.9950 - val_loss: 0.0744 - val_accuracy: 0.9804\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0309 - accuracy: 0.9956 - val_loss: 0.0732 - val_accuracy: 0.9805\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0283 - accuracy: 0.9967 - val_loss: 0.0792 - val_accuracy: 0.9797\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0263 - accuracy: 0.9974 - val_loss: 0.0753 - val_accuracy: 0.9791\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0243 - accuracy: 0.9979 - val_loss: 0.0753 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0231 - accuracy: 0.9983 - val_loss: 0.0747 - val_accuracy: 0.9805\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0216 - accuracy: 0.9986 - val_loss: 0.0760 - val_accuracy: 0.9804\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0204 - accuracy: 0.9989 - val_loss: 0.0732 - val_accuracy: 0.9815\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0196 - accuracy: 0.9991 - val_loss: 0.0732 - val_accuracy: 0.9817\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0185 - accuracy: 0.9994 - val_loss: 0.0751 - val_accuracy: 0.9816\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0177 - accuracy: 0.9995 - val_loss: 0.0731 - val_accuracy: 0.9812\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0172 - accuracy: 0.9995 - val_loss: 0.0726 - val_accuracy: 0.9818\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0165 - accuracy: 0.9997 - val_loss: 0.0735 - val_accuracy: 0.9820\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0160 - accuracy: 0.9998 - val_loss: 0.0740 - val_accuracy: 0.9816\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0156 - accuracy: 0.9998 - val_loss: 0.0746 - val_accuracy: 0.9820\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0153 - accuracy: 0.9999 - val_loss: 0.0741 - val_accuracy: 0.9822\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0736 - val_accuracy: 0.9819\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 0.0745 - val_accuracy: 0.9821\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0145 - accuracy: 0.9999 - val_loss: 0.0752 - val_accuracy: 0.9815\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9815\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9818\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9823\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9817\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9820\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9818\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9824\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9823\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 0.4107 - accuracy: 0.8880 - val_loss: 0.2255 - val_accuracy: 0.9397\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2011 - accuracy: 0.9450 - val_loss: 0.1645 - val_accuracy: 0.9533\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1490 - accuracy: 0.9603 - val_loss: 0.1331 - val_accuracy: 0.9630\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1191 - accuracy: 0.9687 - val_loss: 0.1262 - val_accuracy: 0.9640\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0990 - accuracy: 0.9746 - val_loss: 0.1012 - val_accuracy: 0.9706\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0846 - accuracy: 0.9789 - val_loss: 0.0961 - val_accuracy: 0.9728\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0732 - accuracy: 0.9827 - val_loss: 0.0932 - val_accuracy: 0.9741\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0647 - accuracy: 0.9850 - val_loss: 0.0835 - val_accuracy: 0.9770\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0568 - accuracy: 0.9874 - val_loss: 0.0832 - val_accuracy: 0.9764\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0517 - accuracy: 0.9890 - val_loss: 0.0779 - val_accuracy: 0.9772\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0453 - accuracy: 0.9914 - val_loss: 0.0775 - val_accuracy: 0.9777\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9926 - val_loss: 0.0764 - val_accuracy: 0.9788\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0371 - accuracy: 0.9938 - val_loss: 0.0752 - val_accuracy: 0.9789\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0339 - accuracy: 0.9948 - val_loss: 0.0726 - val_accuracy: 0.9807\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0308 - accuracy: 0.9957 - val_loss: 0.0724 - val_accuracy: 0.9805\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0286 - accuracy: 0.9965 - val_loss: 0.0790 - val_accuracy: 0.9785\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0264 - accuracy: 0.9972 - val_loss: 0.0710 - val_accuracy: 0.9803\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0245 - accuracy: 0.9977 - val_loss: 0.0707 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0229 - accuracy: 0.9984 - val_loss: 0.0738 - val_accuracy: 0.9797\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0215 - accuracy: 0.9987 - val_loss: 0.0731 - val_accuracy: 0.9814\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0205 - accuracy: 0.9989 - val_loss: 0.0743 - val_accuracy: 0.9793\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0193 - accuracy: 0.9991 - val_loss: 0.0729 - val_accuracy: 0.9811\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0184 - accuracy: 0.9994 - val_loss: 0.0716 - val_accuracy: 0.9805\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0176 - accuracy: 0.9995 - val_loss: 0.0723 - val_accuracy: 0.9800\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0171 - accuracy: 0.9996 - val_loss: 0.0716 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0165 - accuracy: 0.9997 - val_loss: 0.0724 - val_accuracy: 0.9800\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0160 - accuracy: 0.9997 - val_loss: 0.0719 - val_accuracy: 0.9811\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0155 - accuracy: 0.9998 - val_loss: 0.0724 - val_accuracy: 0.9809\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0151 - accuracy: 0.9999 - val_loss: 0.0725 - val_accuracy: 0.9811\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0738 - val_accuracy: 0.9810\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 0.0744 - val_accuracy: 0.9799\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0144 - accuracy: 0.9999 - val_loss: 0.0738 - val_accuracy: 0.9815\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0142 - accuracy: 0.9999 - val_loss: 0.0735 - val_accuracy: 0.9811\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9812\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0138 - accuracy: 0.9999 - val_loss: 0.0739 - val_accuracy: 0.9813\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9812\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9806\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9817\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9810\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9810\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 5s 9ms/step - loss: 0.4129 - accuracy: 0.8876 - val_loss: 0.2292 - val_accuracy: 0.9355\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2026 - accuracy: 0.9434 - val_loss: 0.1704 - val_accuracy: 0.9495\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1502 - accuracy: 0.9596 - val_loss: 0.1371 - val_accuracy: 0.9621\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1207 - accuracy: 0.9685 - val_loss: 0.1179 - val_accuracy: 0.9656\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0999 - accuracy: 0.9742 - val_loss: 0.1056 - val_accuracy: 0.9711\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0855 - accuracy: 0.9784 - val_loss: 0.1019 - val_accuracy: 0.9712\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0740 - accuracy: 0.9818 - val_loss: 0.0955 - val_accuracy: 0.9736\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0651 - accuracy: 0.9851 - val_loss: 0.0908 - val_accuracy: 0.9752\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0582 - accuracy: 0.9872 - val_loss: 0.0841 - val_accuracy: 0.9766\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0515 - accuracy: 0.9890 - val_loss: 0.0802 - val_accuracy: 0.9786\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0460 - accuracy: 0.9908 - val_loss: 0.0738 - val_accuracy: 0.9789\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0420 - accuracy: 0.9920 - val_loss: 0.0770 - val_accuracy: 0.9785\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0380 - accuracy: 0.9932 - val_loss: 0.0777 - val_accuracy: 0.9791\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0346 - accuracy: 0.9942 - val_loss: 0.0731 - val_accuracy: 0.9804\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0315 - accuracy: 0.9954 - val_loss: 0.0731 - val_accuracy: 0.9811\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0291 - accuracy: 0.9962 - val_loss: 0.0754 - val_accuracy: 0.9797\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0268 - accuracy: 0.9970 - val_loss: 0.0898 - val_accuracy: 0.9748\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0251 - accuracy: 0.9973 - val_loss: 0.0698 - val_accuracy: 0.9813\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0233 - accuracy: 0.9983 - val_loss: 0.0715 - val_accuracy: 0.9810\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0221 - accuracy: 0.9984 - val_loss: 0.0720 - val_accuracy: 0.9807\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0207 - accuracy: 0.9989 - val_loss: 0.0730 - val_accuracy: 0.9811\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.0706 - val_accuracy: 0.9814\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0188 - accuracy: 0.9993 - val_loss: 0.0714 - val_accuracy: 0.9816\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0180 - accuracy: 0.9995 - val_loss: 0.0733 - val_accuracy: 0.9814\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0175 - accuracy: 0.9995 - val_loss: 0.0739 - val_accuracy: 0.9814\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0167 - accuracy: 0.9997 - val_loss: 0.0718 - val_accuracy: 0.9820\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0163 - accuracy: 0.9997 - val_loss: 0.0726 - val_accuracy: 0.9809\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.9998 - val_loss: 0.0722 - val_accuracy: 0.9821\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0155 - accuracy: 0.9998 - val_loss: 0.0724 - val_accuracy: 0.9814\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0151 - accuracy: 0.9998 - val_loss: 0.0732 - val_accuracy: 0.9813\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0148 - accuracy: 0.9999 - val_loss: 0.0729 - val_accuracy: 0.9823\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 0.0726 - val_accuracy: 0.9818\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0144 - accuracy: 0.9999 - val_loss: 0.0731 - val_accuracy: 0.9826\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0142 - accuracy: 0.9999 - val_loss: 0.0742 - val_accuracy: 0.9814\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9818\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9821\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9818\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9820\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9821\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9823\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4997 - accuracy: 0.8902 - val_loss: 0.3187 - val_accuracy: 0.9364\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2903 - accuracy: 0.9450 - val_loss: 0.2766 - val_accuracy: 0.9467\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2402 - accuracy: 0.9596 - val_loss: 0.2294 - val_accuracy: 0.9605\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2095 - accuracy: 0.9679 - val_loss: 0.2095 - val_accuracy: 0.9660\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1882 - accuracy: 0.9744 - val_loss: 0.1975 - val_accuracy: 0.9710\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1726 - accuracy: 0.9787 - val_loss: 0.1837 - val_accuracy: 0.9730\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1611 - accuracy: 0.9815 - val_loss: 0.1733 - val_accuracy: 0.9758\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1513 - accuracy: 0.9842 - val_loss: 0.1790 - val_accuracy: 0.9730\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1429 - accuracy: 0.9863 - val_loss: 0.1694 - val_accuracy: 0.9764\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1364 - accuracy: 0.9883 - val_loss: 0.1627 - val_accuracy: 0.9764\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1304 - accuracy: 0.9901 - val_loss: 0.1612 - val_accuracy: 0.9775\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1245 - accuracy: 0.9915 - val_loss: 0.1680 - val_accuracy: 0.9736\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1198 - accuracy: 0.9926 - val_loss: 0.1531 - val_accuracy: 0.9788\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1155 - accuracy: 0.9935 - val_loss: 0.1522 - val_accuracy: 0.9799\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1119 - accuracy: 0.9946 - val_loss: 0.1513 - val_accuracy: 0.9779\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1081 - accuracy: 0.9958 - val_loss: 0.1551 - val_accuracy: 0.9772\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1050 - accuracy: 0.9962 - val_loss: 0.1481 - val_accuracy: 0.9797\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1020 - accuracy: 0.9969 - val_loss: 0.1444 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0993 - accuracy: 0.9975 - val_loss: 0.1441 - val_accuracy: 0.9806\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0967 - accuracy: 0.9980 - val_loss: 0.1416 - val_accuracy: 0.9807\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0944 - accuracy: 0.9982 - val_loss: 0.1405 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0922 - accuracy: 0.9985 - val_loss: 0.1403 - val_accuracy: 0.9805\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0902 - accuracy: 0.9988 - val_loss: 0.1395 - val_accuracy: 0.9795\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0885 - accuracy: 0.9990 - val_loss: 0.1401 - val_accuracy: 0.9799\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0867 - accuracy: 0.9990 - val_loss: 0.1357 - val_accuracy: 0.9810\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0850 - accuracy: 0.9993 - val_loss: 0.1342 - val_accuracy: 0.9807\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0834 - accuracy: 0.9993 - val_loss: 0.1344 - val_accuracy: 0.9803\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0818 - accuracy: 0.9995 - val_loss: 0.1316 - val_accuracy: 0.9810\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0803 - accuracy: 0.9997 - val_loss: 0.1311 - val_accuracy: 0.9816\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0789 - accuracy: 0.9997 - val_loss: 0.1313 - val_accuracy: 0.9806\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0776 - accuracy: 0.9997 - val_loss: 0.1299 - val_accuracy: 0.9801\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0763 - accuracy: 0.9998 - val_loss: 0.1281 - val_accuracy: 0.9808\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0751 - accuracy: 0.9998 - val_loss: 0.1270 - val_accuracy: 0.9807\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0739 - accuracy: 0.9998 - val_loss: 0.1263 - val_accuracy: 0.9808\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0727 - accuracy: 0.9999 - val_loss: 0.1245 - val_accuracy: 0.9805\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0716 - accuracy: 0.9999 - val_loss: 0.1245 - val_accuracy: 0.9806\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0705 - accuracy: 0.9998 - val_loss: 0.1221 - val_accuracy: 0.9814\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0694 - accuracy: 0.9999 - val_loss: 0.1220 - val_accuracy: 0.9810\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0684 - accuracy: 0.9999 - val_loss: 0.1215 - val_accuracy: 0.9810\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9999 - val_loss: 0.1208 - val_accuracy: 0.9804\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4944 - accuracy: 0.8909 - val_loss: 0.3095 - val_accuracy: 0.9380\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2882 - accuracy: 0.9456 - val_loss: 0.2561 - val_accuracy: 0.9531\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2381 - accuracy: 0.9603 - val_loss: 0.2223 - val_accuracy: 0.9623\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2087 - accuracy: 0.9686 - val_loss: 0.2022 - val_accuracy: 0.9694\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1885 - accuracy: 0.9736 - val_loss: 0.1939 - val_accuracy: 0.9709\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1733 - accuracy: 0.9778 - val_loss: 0.1876 - val_accuracy: 0.9720\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1605 - accuracy: 0.9815 - val_loss: 0.1861 - val_accuracy: 0.9705\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1510 - accuracy: 0.9840 - val_loss: 0.1683 - val_accuracy: 0.9768\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1427 - accuracy: 0.9866 - val_loss: 0.1632 - val_accuracy: 0.9775\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1355 - accuracy: 0.9887 - val_loss: 0.1645 - val_accuracy: 0.9767\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1299 - accuracy: 0.9898 - val_loss: 0.1595 - val_accuracy: 0.9792\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1241 - accuracy: 0.9917 - val_loss: 0.1560 - val_accuracy: 0.9793\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1191 - accuracy: 0.9931 - val_loss: 0.1538 - val_accuracy: 0.9798\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1149 - accuracy: 0.9940 - val_loss: 0.1550 - val_accuracy: 0.9787\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1110 - accuracy: 0.9948 - val_loss: 0.1527 - val_accuracy: 0.9788\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1077 - accuracy: 0.9955 - val_loss: 0.1480 - val_accuracy: 0.9798\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1042 - accuracy: 0.9963 - val_loss: 0.1451 - val_accuracy: 0.9808\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1014 - accuracy: 0.9972 - val_loss: 0.1428 - val_accuracy: 0.9811\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0988 - accuracy: 0.9976 - val_loss: 0.1424 - val_accuracy: 0.9809\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0962 - accuracy: 0.9981 - val_loss: 0.1418 - val_accuracy: 0.9818\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0941 - accuracy: 0.9982 - val_loss: 0.1396 - val_accuracy: 0.9805\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0918 - accuracy: 0.9988 - val_loss: 0.1394 - val_accuracy: 0.9810\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0899 - accuracy: 0.9988 - val_loss: 0.1470 - val_accuracy: 0.9774\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0880 - accuracy: 0.9992 - val_loss: 0.1427 - val_accuracy: 0.9793\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0864 - accuracy: 0.9991 - val_loss: 0.1368 - val_accuracy: 0.9815\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0846 - accuracy: 0.9992 - val_loss: 0.1343 - val_accuracy: 0.9811\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0829 - accuracy: 0.9995 - val_loss: 0.1330 - val_accuracy: 0.9815\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0814 - accuracy: 0.9996 - val_loss: 0.1304 - val_accuracy: 0.9819\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0800 - accuracy: 0.9996 - val_loss: 0.1308 - val_accuracy: 0.9808\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0786 - accuracy: 0.9997 - val_loss: 0.1301 - val_accuracy: 0.9817\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0772 - accuracy: 0.9998 - val_loss: 0.1288 - val_accuracy: 0.9818\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0761 - accuracy: 0.9998 - val_loss: 0.1273 - val_accuracy: 0.9818\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0747 - accuracy: 0.9998 - val_loss: 0.1260 - val_accuracy: 0.9818\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0735 - accuracy: 0.9999 - val_loss: 0.1263 - val_accuracy: 0.9819\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0723 - accuracy: 0.9998 - val_loss: 0.1251 - val_accuracy: 0.9813\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0713 - accuracy: 0.9999 - val_loss: 0.1234 - val_accuracy: 0.9821\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0701 - accuracy: 0.9999 - val_loss: 0.1216 - val_accuracy: 0.9825\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0691 - accuracy: 0.9999 - val_loss: 0.1220 - val_accuracy: 0.9813\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0680 - accuracy: 0.9999 - val_loss: 0.1199 - val_accuracy: 0.9829\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0670 - accuracy: 0.9999 - val_loss: 0.1195 - val_accuracy: 0.9813\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5033 - accuracy: 0.8875 - val_loss: 0.3317 - val_accuracy: 0.9315\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2942 - accuracy: 0.9438 - val_loss: 0.2528 - val_accuracy: 0.9530\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2410 - accuracy: 0.9584 - val_loss: 0.2239 - val_accuracy: 0.9619\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2104 - accuracy: 0.9674 - val_loss: 0.2075 - val_accuracy: 0.9668\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1898 - accuracy: 0.9736 - val_loss: 0.1917 - val_accuracy: 0.9706\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1744 - accuracy: 0.9776 - val_loss: 0.1822 - val_accuracy: 0.9736\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1620 - accuracy: 0.9813 - val_loss: 0.1763 - val_accuracy: 0.9744\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1525 - accuracy: 0.9837 - val_loss: 0.1773 - val_accuracy: 0.9746\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1438 - accuracy: 0.9854 - val_loss: 0.1745 - val_accuracy: 0.9754\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1369 - accuracy: 0.9876 - val_loss: 0.1618 - val_accuracy: 0.9784\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1308 - accuracy: 0.9895 - val_loss: 0.1570 - val_accuracy: 0.9790\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1248 - accuracy: 0.9910 - val_loss: 0.1568 - val_accuracy: 0.9793\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1201 - accuracy: 0.9925 - val_loss: 0.1550 - val_accuracy: 0.9777\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1154 - accuracy: 0.9938 - val_loss: 0.1553 - val_accuracy: 0.9798\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1115 - accuracy: 0.9949 - val_loss: 0.1509 - val_accuracy: 0.9796\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1081 - accuracy: 0.9955 - val_loss: 0.1449 - val_accuracy: 0.9795\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1046 - accuracy: 0.9963 - val_loss: 0.1493 - val_accuracy: 0.9802\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1020 - accuracy: 0.9969 - val_loss: 0.1430 - val_accuracy: 0.9802\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0989 - accuracy: 0.9976 - val_loss: 0.1414 - val_accuracy: 0.9806\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0967 - accuracy: 0.9980 - val_loss: 0.1392 - val_accuracy: 0.9808\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0942 - accuracy: 0.9983 - val_loss: 0.1417 - val_accuracy: 0.9798\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0919 - accuracy: 0.9987 - val_loss: 0.1446 - val_accuracy: 0.9792\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0900 - accuracy: 0.9988 - val_loss: 0.1365 - val_accuracy: 0.9804\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0882 - accuracy: 0.9989 - val_loss: 0.1346 - val_accuracy: 0.9814\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0864 - accuracy: 0.9991 - val_loss: 0.1352 - val_accuracy: 0.9807\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0849 - accuracy: 0.9993 - val_loss: 0.1335 - val_accuracy: 0.9809\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0831 - accuracy: 0.9994 - val_loss: 0.1326 - val_accuracy: 0.9810\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0817 - accuracy: 0.9995 - val_loss: 0.1313 - val_accuracy: 0.9810\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0801 - accuracy: 0.9995 - val_loss: 0.1309 - val_accuracy: 0.9805\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0787 - accuracy: 0.9997 - val_loss: 0.1281 - val_accuracy: 0.9813\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0774 - accuracy: 0.9997 - val_loss: 0.1281 - val_accuracy: 0.9811\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0760 - accuracy: 0.9997 - val_loss: 0.1265 - val_accuracy: 0.9811\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0748 - accuracy: 0.9998 - val_loss: 0.1260 - val_accuracy: 0.9807\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0736 - accuracy: 0.9998 - val_loss: 0.1246 - val_accuracy: 0.9815\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0724 - accuracy: 0.9998 - val_loss: 0.1253 - val_accuracy: 0.9810\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0713 - accuracy: 0.9999 - val_loss: 0.1234 - val_accuracy: 0.9810\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0702 - accuracy: 0.9999 - val_loss: 0.1224 - val_accuracy: 0.9808\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0692 - accuracy: 0.9999 - val_loss: 0.1208 - val_accuracy: 0.9804\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0680 - accuracy: 0.9999 - val_loss: 0.1202 - val_accuracy: 0.9806\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0670 - accuracy: 0.9999 - val_loss: 0.1184 - val_accuracy: 0.9818\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5454 - accuracy: 0.8899 - val_loss: 0.3646 - val_accuracy: 0.9371\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3347 - accuracy: 0.9459 - val_loss: 0.3000 - val_accuracy: 0.9558\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2831 - accuracy: 0.9607 - val_loss: 0.2683 - val_accuracy: 0.9636\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2521 - accuracy: 0.9680 - val_loss: 0.2469 - val_accuracy: 0.9703\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2310 - accuracy: 0.9742 - val_loss: 0.2356 - val_accuracy: 0.9710\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2150 - accuracy: 0.9784 - val_loss: 0.2266 - val_accuracy: 0.9726\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2020 - accuracy: 0.9816 - val_loss: 0.2169 - val_accuracy: 0.9726\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1902 - accuracy: 0.9846 - val_loss: 0.2121 - val_accuracy: 0.9763\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1817 - accuracy: 0.9859 - val_loss: 0.2085 - val_accuracy: 0.9765\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1732 - accuracy: 0.9879 - val_loss: 0.1970 - val_accuracy: 0.9787\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1661 - accuracy: 0.9893 - val_loss: 0.1945 - val_accuracy: 0.9775\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1595 - accuracy: 0.9905 - val_loss: 0.1928 - val_accuracy: 0.9790\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1534 - accuracy: 0.9919 - val_loss: 0.1864 - val_accuracy: 0.9800\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1476 - accuracy: 0.9931 - val_loss: 0.2035 - val_accuracy: 0.9737\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1423 - accuracy: 0.9942 - val_loss: 0.1767 - val_accuracy: 0.9802\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1375 - accuracy: 0.9952 - val_loss: 0.1820 - val_accuracy: 0.9784\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1331 - accuracy: 0.9958 - val_loss: 0.1741 - val_accuracy: 0.9790\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1289 - accuracy: 0.9965 - val_loss: 0.1695 - val_accuracy: 0.9799\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1254 - accuracy: 0.9969 - val_loss: 0.1692 - val_accuracy: 0.9809\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1213 - accuracy: 0.9978 - val_loss: 0.1642 - val_accuracy: 0.9815\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1180 - accuracy: 0.9977 - val_loss: 0.1647 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1148 - accuracy: 0.9982 - val_loss: 0.1628 - val_accuracy: 0.9799\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1118 - accuracy: 0.9987 - val_loss: 0.1578 - val_accuracy: 0.9808\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1087 - accuracy: 0.9989 - val_loss: 0.1556 - val_accuracy: 0.9818\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1061 - accuracy: 0.9991 - val_loss: 0.1524 - val_accuracy: 0.9816\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1036 - accuracy: 0.9993 - val_loss: 0.1528 - val_accuracy: 0.9815\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1010 - accuracy: 0.9992 - val_loss: 0.1487 - val_accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0987 - accuracy: 0.9993 - val_loss: 0.1480 - val_accuracy: 0.9819\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0964 - accuracy: 0.9994 - val_loss: 0.1454 - val_accuracy: 0.9815\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0943 - accuracy: 0.9994 - val_loss: 0.1482 - val_accuracy: 0.9804\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0921 - accuracy: 0.9996 - val_loss: 0.1420 - val_accuracy: 0.9827\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0900 - accuracy: 0.9997 - val_loss: 0.1423 - val_accuracy: 0.9812\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0881 - accuracy: 0.9996 - val_loss: 0.1397 - val_accuracy: 0.9811\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0861 - accuracy: 0.9997 - val_loss: 0.1368 - val_accuracy: 0.9821\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - accuracy: 0.9998 - val_loss: 0.1354 - val_accuracy: 0.9819\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0825 - accuracy: 0.9998 - val_loss: 0.1325 - val_accuracy: 0.9823\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0809 - accuracy: 0.9998 - val_loss: 0.1300 - val_accuracy: 0.9818\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0791 - accuracy: 0.9998 - val_loss: 0.1296 - val_accuracy: 0.9831\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0775 - accuracy: 0.9998 - val_loss: 0.1268 - val_accuracy: 0.9821\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0759 - accuracy: 0.9999 - val_loss: 0.1258 - val_accuracy: 0.9825\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5547 - accuracy: 0.8869 - val_loss: 0.3634 - val_accuracy: 0.9376\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3372 - accuracy: 0.9454 - val_loss: 0.2994 - val_accuracy: 0.9542\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2838 - accuracy: 0.9606 - val_loss: 0.2613 - val_accuracy: 0.9661\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2523 - accuracy: 0.9686 - val_loss: 0.2564 - val_accuracy: 0.9648\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2305 - accuracy: 0.9742 - val_loss: 0.2372 - val_accuracy: 0.9702\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2123 - accuracy: 0.9790 - val_loss: 0.2230 - val_accuracy: 0.9736\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1997 - accuracy: 0.9818 - val_loss: 0.2165 - val_accuracy: 0.9743\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1888 - accuracy: 0.9847 - val_loss: 0.2062 - val_accuracy: 0.9755\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1791 - accuracy: 0.9869 - val_loss: 0.2032 - val_accuracy: 0.9764\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1708 - accuracy: 0.9888 - val_loss: 0.1948 - val_accuracy: 0.9782\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1642 - accuracy: 0.9896 - val_loss: 0.1956 - val_accuracy: 0.9774\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1574 - accuracy: 0.9911 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1515 - accuracy: 0.9922 - val_loss: 0.1874 - val_accuracy: 0.9798\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1454 - accuracy: 0.9936 - val_loss: 0.1820 - val_accuracy: 0.9790\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1407 - accuracy: 0.9948 - val_loss: 0.1788 - val_accuracy: 0.9791\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1359 - accuracy: 0.9951 - val_loss: 0.1740 - val_accuracy: 0.9800\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1316 - accuracy: 0.9960 - val_loss: 0.1745 - val_accuracy: 0.9794\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1277 - accuracy: 0.9967 - val_loss: 0.1697 - val_accuracy: 0.9804\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1238 - accuracy: 0.9974 - val_loss: 0.1678 - val_accuracy: 0.9808\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1205 - accuracy: 0.9978 - val_loss: 0.1695 - val_accuracy: 0.9796\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1169 - accuracy: 0.9980 - val_loss: 0.1617 - val_accuracy: 0.9807\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1139 - accuracy: 0.9984 - val_loss: 0.1587 - val_accuracy: 0.9813\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1108 - accuracy: 0.9987 - val_loss: 0.1564 - val_accuracy: 0.9811\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1080 - accuracy: 0.9987 - val_loss: 0.1557 - val_accuracy: 0.9808\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1055 - accuracy: 0.9989 - val_loss: 0.1524 - val_accuracy: 0.9815\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1027 - accuracy: 0.9993 - val_loss: 0.1518 - val_accuracy: 0.9811\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1003 - accuracy: 0.9993 - val_loss: 0.1566 - val_accuracy: 0.9791\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0979 - accuracy: 0.9995 - val_loss: 0.1461 - val_accuracy: 0.9826\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0956 - accuracy: 0.9994 - val_loss: 0.1448 - val_accuracy: 0.9812\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0935 - accuracy: 0.9995 - val_loss: 0.1432 - val_accuracy: 0.9812\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0914 - accuracy: 0.9996 - val_loss: 0.1412 - val_accuracy: 0.9817\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0893 - accuracy: 0.9995 - val_loss: 0.1402 - val_accuracy: 0.9814\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0874 - accuracy: 0.9997 - val_loss: 0.1371 - val_accuracy: 0.9823\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0855 - accuracy: 0.9997 - val_loss: 0.1370 - val_accuracy: 0.9811\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0836 - accuracy: 0.9997 - val_loss: 0.1335 - val_accuracy: 0.9820\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0819 - accuracy: 0.9998 - val_loss: 0.1320 - val_accuracy: 0.9816\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0801 - accuracy: 0.9999 - val_loss: 0.1302 - val_accuracy: 0.9823\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0784 - accuracy: 0.9998 - val_loss: 0.1286 - val_accuracy: 0.9822\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0769 - accuracy: 0.9998 - val_loss: 0.1264 - val_accuracy: 0.9818\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0753 - accuracy: 0.9998 - val_loss: 0.1256 - val_accuracy: 0.9817\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.5473 - accuracy: 0.8902 - val_loss: 0.3719 - val_accuracy: 0.9372\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3395 - accuracy: 0.9446 - val_loss: 0.3093 - val_accuracy: 0.9515\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2873 - accuracy: 0.9589 - val_loss: 0.2738 - val_accuracy: 0.9629\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2547 - accuracy: 0.9682 - val_loss: 0.2451 - val_accuracy: 0.9695\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2327 - accuracy: 0.9737 - val_loss: 0.2334 - val_accuracy: 0.9717\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2159 - accuracy: 0.9782 - val_loss: 0.2235 - val_accuracy: 0.9730\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2020 - accuracy: 0.9816 - val_loss: 0.2128 - val_accuracy: 0.9762\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1917 - accuracy: 0.9837 - val_loss: 0.2028 - val_accuracy: 0.9772\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1810 - accuracy: 0.9865 - val_loss: 0.2012 - val_accuracy: 0.9779\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1725 - accuracy: 0.9882 - val_loss: 0.1920 - val_accuracy: 0.9801\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1653 - accuracy: 0.9896 - val_loss: 0.1957 - val_accuracy: 0.9782\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1587 - accuracy: 0.9907 - val_loss: 0.1928 - val_accuracy: 0.9766\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1524 - accuracy: 0.9923 - val_loss: 0.1848 - val_accuracy: 0.9801\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1469 - accuracy: 0.9935 - val_loss: 0.1774 - val_accuracy: 0.9803\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1416 - accuracy: 0.9943 - val_loss: 0.1764 - val_accuracy: 0.9801\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1367 - accuracy: 0.9952 - val_loss: 0.1724 - val_accuracy: 0.9812\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1323 - accuracy: 0.9963 - val_loss: 0.1688 - val_accuracy: 0.9812\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1282 - accuracy: 0.9966 - val_loss: 0.1647 - val_accuracy: 0.9832\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1244 - accuracy: 0.9975 - val_loss: 0.1623 - val_accuracy: 0.9827\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1207 - accuracy: 0.9977 - val_loss: 0.1596 - val_accuracy: 0.9822\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1176 - accuracy: 0.9980 - val_loss: 0.1560 - val_accuracy: 0.9832\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1143 - accuracy: 0.9984 - val_loss: 0.1564 - val_accuracy: 0.9816\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1114 - accuracy: 0.9984 - val_loss: 0.1526 - val_accuracy: 0.9831\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1086 - accuracy: 0.9987 - val_loss: 0.1501 - val_accuracy: 0.9831\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1059 - accuracy: 0.9990 - val_loss: 0.1478 - val_accuracy: 0.9839\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1031 - accuracy: 0.9991 - val_loss: 0.1465 - val_accuracy: 0.9835\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1006 - accuracy: 0.9993 - val_loss: 0.1434 - val_accuracy: 0.9831\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0983 - accuracy: 0.9993 - val_loss: 0.1438 - val_accuracy: 0.9828\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0959 - accuracy: 0.9995 - val_loss: 0.1401 - val_accuracy: 0.9841\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0937 - accuracy: 0.9995 - val_loss: 0.1375 - val_accuracy: 0.9835\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0915 - accuracy: 0.9996 - val_loss: 0.1373 - val_accuracy: 0.9831\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0896 - accuracy: 0.9997 - val_loss: 0.1345 - val_accuracy: 0.9836\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0876 - accuracy: 0.9997 - val_loss: 0.1321 - val_accuracy: 0.9835\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0857 - accuracy: 0.9997 - val_loss: 0.1307 - val_accuracy: 0.9828\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0839 - accuracy: 0.9998 - val_loss: 0.1306 - val_accuracy: 0.9834\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0821 - accuracy: 0.9998 - val_loss: 0.1297 - val_accuracy: 0.9826\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0804 - accuracy: 0.9998 - val_loss: 0.1273 - val_accuracy: 0.9828\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0788 - accuracy: 0.9998 - val_loss: 0.1245 - val_accuracy: 0.9844\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0771 - accuracy: 0.9999 - val_loss: 0.1245 - val_accuracy: 0.9828\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0755 - accuracy: 0.9998 - val_loss: 0.1227 - val_accuracy: 0.9832\n",
      "... still running\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 1.3300 - accuracy: 0.8870 - val_loss: 1.0820 - val_accuracy: 0.9345\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.9798 - accuracy: 0.9430 - val_loss: 0.8791 - val_accuracy: 0.9538\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.8126 - accuracy: 0.9577 - val_loss: 0.7458 - val_accuracy: 0.9598\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6864 - accuracy: 0.9655 - val_loss: 0.6426 - val_accuracy: 0.9636\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5860 - accuracy: 0.9712 - val_loss: 0.5541 - val_accuracy: 0.9681\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5053 - accuracy: 0.9743 - val_loss: 0.4799 - val_accuracy: 0.9700\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4377 - accuracy: 0.9768 - val_loss: 0.4220 - val_accuracy: 0.9723\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.9795 - val_loss: 0.3798 - val_accuracy: 0.9722\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3367 - accuracy: 0.9811 - val_loss: 0.3357 - val_accuracy: 0.9738\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2989 - accuracy: 0.9829 - val_loss: 0.2982 - val_accuracy: 0.9755\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2670 - accuracy: 0.9839 - val_loss: 0.2750 - val_accuracy: 0.9752\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2416 - accuracy: 0.9844 - val_loss: 0.2511 - val_accuracy: 0.9757\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2184 - accuracy: 0.9857 - val_loss: 0.2326 - val_accuracy: 0.9747\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2008 - accuracy: 0.9857 - val_loss: 0.2149 - val_accuracy: 0.9775\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1844 - accuracy: 0.9877 - val_loss: 0.1947 - val_accuracy: 0.9796\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1714 - accuracy: 0.9876 - val_loss: 0.1885 - val_accuracy: 0.9782\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.9879 - val_loss: 0.1728 - val_accuracy: 0.9807\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1504 - accuracy: 0.9887 - val_loss: 0.1659 - val_accuracy: 0.9807\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1424 - accuracy: 0.9888 - val_loss: 0.1621 - val_accuracy: 0.9792\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1362 - accuracy: 0.9889 - val_loss: 0.1521 - val_accuracy: 0.9803\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1297 - accuracy: 0.9895 - val_loss: 0.1469 - val_accuracy: 0.9814\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1244 - accuracy: 0.9904 - val_loss: 0.1431 - val_accuracy: 0.9807\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1205 - accuracy: 0.9901 - val_loss: 0.1423 - val_accuracy: 0.9796\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1171 - accuracy: 0.9900 - val_loss: 0.1394 - val_accuracy: 0.9797\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1133 - accuracy: 0.9906 - val_loss: 0.1383 - val_accuracy: 0.9810\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1102 - accuracy: 0.9910 - val_loss: 0.1363 - val_accuracy: 0.9806\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1081 - accuracy: 0.9910 - val_loss: 0.1319 - val_accuracy: 0.9805\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1049 - accuracy: 0.9917 - val_loss: 0.1273 - val_accuracy: 0.9823\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1033 - accuracy: 0.9921 - val_loss: 0.1288 - val_accuracy: 0.9802\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1013 - accuracy: 0.9919 - val_loss: 0.1253 - val_accuracy: 0.9815\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0999 - accuracy: 0.9922 - val_loss: 0.1311 - val_accuracy: 0.9789\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0982 - accuracy: 0.9922 - val_loss: 0.1259 - val_accuracy: 0.9786\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0965 - accuracy: 0.9931 - val_loss: 0.1242 - val_accuracy: 0.9805\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0960 - accuracy: 0.9922 - val_loss: 0.1340 - val_accuracy: 0.9755\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0949 - accuracy: 0.9928 - val_loss: 0.1197 - val_accuracy: 0.9814\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0933 - accuracy: 0.9931 - val_loss: 0.1215 - val_accuracy: 0.9808\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0928 - accuracy: 0.9928 - val_loss: 0.1221 - val_accuracy: 0.9806\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0912 - accuracy: 0.9935 - val_loss: 0.1269 - val_accuracy: 0.9800\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0904 - accuracy: 0.9933 - val_loss: 0.1185 - val_accuracy: 0.9819\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0896 - accuracy: 0.9937 - val_loss: 0.1177 - val_accuracy: 0.9813\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3258 - accuracy: 0.8879 - val_loss: 1.0707 - val_accuracy: 0.9317\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.9798 - accuracy: 0.9425 - val_loss: 0.8932 - val_accuracy: 0.9461\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.8118 - accuracy: 0.9578 - val_loss: 0.7447 - val_accuracy: 0.9614\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6855 - accuracy: 0.9656 - val_loss: 0.6400 - val_accuracy: 0.9658\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5851 - accuracy: 0.9708 - val_loss: 0.5550 - val_accuracy: 0.9662\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5037 - accuracy: 0.9746 - val_loss: 0.4809 - val_accuracy: 0.9704\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4362 - accuracy: 0.9772 - val_loss: 0.4229 - val_accuracy: 0.9719\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.9797 - val_loss: 0.3853 - val_accuracy: 0.9682\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3360 - accuracy: 0.9807 - val_loss: 0.3287 - val_accuracy: 0.9770\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2985 - accuracy: 0.9826 - val_loss: 0.2948 - val_accuracy: 0.9769\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2668 - accuracy: 0.9837 - val_loss: 0.2810 - val_accuracy: 0.9726\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2400 - accuracy: 0.9847 - val_loss: 0.2481 - val_accuracy: 0.9774\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2176 - accuracy: 0.9863 - val_loss: 0.2263 - val_accuracy: 0.9780\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1994 - accuracy: 0.9861 - val_loss: 0.2117 - val_accuracy: 0.9771\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1836 - accuracy: 0.9870 - val_loss: 0.2086 - val_accuracy: 0.9751\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1703 - accuracy: 0.9881 - val_loss: 0.1841 - val_accuracy: 0.9793\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1598 - accuracy: 0.9881 - val_loss: 0.1735 - val_accuracy: 0.9800\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1505 - accuracy: 0.9888 - val_loss: 0.1716 - val_accuracy: 0.9785\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1421 - accuracy: 0.9893 - val_loss: 0.1640 - val_accuracy: 0.9781\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1356 - accuracy: 0.9893 - val_loss: 0.1559 - val_accuracy: 0.9797\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1292 - accuracy: 0.9902 - val_loss: 0.1505 - val_accuracy: 0.9796\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1241 - accuracy: 0.9902 - val_loss: 0.1443 - val_accuracy: 0.9803\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1201 - accuracy: 0.9902 - val_loss: 0.1421 - val_accuracy: 0.9796\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1167 - accuracy: 0.9904 - val_loss: 0.1419 - val_accuracy: 0.9795\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1134 - accuracy: 0.9906 - val_loss: 0.1370 - val_accuracy: 0.9789\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1098 - accuracy: 0.9915 - val_loss: 0.1329 - val_accuracy: 0.9805\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.1067 - accuracy: 0.9919 - val_loss: 0.1299 - val_accuracy: 0.9813\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1054 - accuracy: 0.9916 - val_loss: 0.1439 - val_accuracy: 0.9767\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1025 - accuracy: 0.9921 - val_loss: 0.1321 - val_accuracy: 0.9786\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1011 - accuracy: 0.9920 - val_loss: 0.1380 - val_accuracy: 0.9766\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0996 - accuracy: 0.9924 - val_loss: 0.1251 - val_accuracy: 0.9808\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0982 - accuracy: 0.9927 - val_loss: 0.1266 - val_accuracy: 0.9807\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0968 - accuracy: 0.9926 - val_loss: 0.1334 - val_accuracy: 0.9785\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0952 - accuracy: 0.9928 - val_loss: 0.1194 - val_accuracy: 0.9819\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0948 - accuracy: 0.9926 - val_loss: 0.1291 - val_accuracy: 0.9783\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0927 - accuracy: 0.9933 - val_loss: 0.1270 - val_accuracy: 0.9788\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0925 - accuracy: 0.9928 - val_loss: 0.1244 - val_accuracy: 0.9801\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0918 - accuracy: 0.9933 - val_loss: 0.1182 - val_accuracy: 0.9810\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0901 - accuracy: 0.9937 - val_loss: 0.1181 - val_accuracy: 0.9810\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0902 - accuracy: 0.9935 - val_loss: 0.1271 - val_accuracy: 0.9765\n",
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 1.3239 - accuracy: 0.8889 - val_loss: 1.0779 - val_accuracy: 0.9344\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.9819 - accuracy: 0.9425 - val_loss: 0.8827 - val_accuracy: 0.9524\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.8141 - accuracy: 0.9575 - val_loss: 0.7388 - val_accuracy: 0.9616\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6863 - accuracy: 0.9657 - val_loss: 0.6382 - val_accuracy: 0.9652\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5861 - accuracy: 0.9707 - val_loss: 0.5519 - val_accuracy: 0.9677\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5045 - accuracy: 0.9741 - val_loss: 0.4792 - val_accuracy: 0.9713\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.4377 - accuracy: 0.9770 - val_loss: 0.4335 - val_accuracy: 0.9692\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.9790 - val_loss: 0.3883 - val_accuracy: 0.9675\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3367 - accuracy: 0.9812 - val_loss: 0.3295 - val_accuracy: 0.9751\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2992 - accuracy: 0.9825 - val_loss: 0.2985 - val_accuracy: 0.9759\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2666 - accuracy: 0.9836 - val_loss: 0.2718 - val_accuracy: 0.9759\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2405 - accuracy: 0.9848 - val_loss: 0.2482 - val_accuracy: 0.9769\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2188 - accuracy: 0.9858 - val_loss: 0.2257 - val_accuracy: 0.9782\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1998 - accuracy: 0.9866 - val_loss: 0.2073 - val_accuracy: 0.9802\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1845 - accuracy: 0.9868 - val_loss: 0.1965 - val_accuracy: 0.9799\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1711 - accuracy: 0.9878 - val_loss: 0.1879 - val_accuracy: 0.9779\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1598 - accuracy: 0.9883 - val_loss: 0.1841 - val_accuracy: 0.9766\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1500 - accuracy: 0.9886 - val_loss: 0.1718 - val_accuracy: 0.9779\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1421 - accuracy: 0.9888 - val_loss: 0.1571 - val_accuracy: 0.9811\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1359 - accuracy: 0.9893 - val_loss: 0.1665 - val_accuracy: 0.9760\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1288 - accuracy: 0.9901 - val_loss: 0.1481 - val_accuracy: 0.9808\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1243 - accuracy: 0.9899 - val_loss: 0.1548 - val_accuracy: 0.9769\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1204 - accuracy: 0.9901 - val_loss: 0.1428 - val_accuracy: 0.9800\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1159 - accuracy: 0.9904 - val_loss: 0.1405 - val_accuracy: 0.9795\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1126 - accuracy: 0.9907 - val_loss: 0.1370 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1101 - accuracy: 0.9907 - val_loss: 0.1351 - val_accuracy: 0.9809\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1072 - accuracy: 0.9916 - val_loss: 0.1412 - val_accuracy: 0.9764\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1055 - accuracy: 0.9915 - val_loss: 0.1301 - val_accuracy: 0.9806\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1033 - accuracy: 0.9916 - val_loss: 0.1336 - val_accuracy: 0.9785\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1010 - accuracy: 0.9919 - val_loss: 0.1278 - val_accuracy: 0.9806\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0998 - accuracy: 0.9922 - val_loss: 0.1244 - val_accuracy: 0.9821\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0981 - accuracy: 0.9922 - val_loss: 0.1235 - val_accuracy: 0.9820\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0970 - accuracy: 0.9923 - val_loss: 0.1204 - val_accuracy: 0.9816\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0955 - accuracy: 0.9926 - val_loss: 0.1212 - val_accuracy: 0.9820\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0950 - accuracy: 0.9924 - val_loss: 0.1214 - val_accuracy: 0.9812\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0937 - accuracy: 0.9926 - val_loss: 0.1222 - val_accuracy: 0.9805\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0929 - accuracy: 0.9929 - val_loss: 0.1322 - val_accuracy: 0.9759\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0917 - accuracy: 0.9927 - val_loss: 0.1162 - val_accuracy: 0.9824\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0907 - accuracy: 0.9930 - val_loss: 0.1184 - val_accuracy: 0.9813\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0892 - accuracy: 0.9937 - val_loss: 0.1171 - val_accuracy: 0.9814\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers as reg\n",
    "\n",
    "regFactors = [0.000001, 0.00001, 0.0001, 0.00015, 0.001]\n",
    "accuracies_2 = []\n",
    "print('Running...')\n",
    "for factor in regFactors:\n",
    "    print(\"... still running\")\n",
    "    # Train 3 replicates networks for each regularization factor\n",
    "    for replicate in range(3): # 3 replicates\n",
    "        \n",
    "        ## Define model ##\n",
    "        model = Sequential()\n",
    "\n",
    "        # These are our 4 layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500, activation = 'relu', kernel_regularizer=reg.l2(factor))) ## Hidden layer\n",
    "        model.add(Dense(300, activation = 'relu', kernel_regularizer=reg.l2(factor))) ## Hidden layer\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                       optimizer=tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "                metrics=['accuracy'],)\n",
    "\n",
    "        fit_info_2 = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=40, # Train for 40 epochs\n",
    "                   verbose=1, # Silence the background noice \n",
    "                   validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        accuracies_2.append((factor,score[0], score[1]))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8e945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ouput of question 2D to csv.file and dataframe\n",
    "saveOutput(accuracies_2, '2D')\n",
    "df_2D = createDataframe('2D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9dcdffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize \n",
    "means = []\n",
    "sds = []\n",
    "a = df_2D['Test']\n",
    "\n",
    "# 1.Calculate the mean of each set of replicates\n",
    "i = numpy.array([0,3,6,9,12]) # Starting indices \n",
    "j = i+2 # Stop indices\n",
    "\n",
    "for k in range(len(i)):\n",
    "    m = i[k] # Start\n",
    "    n = j[k]+1 # Stop. Indexing differrs by +1 between array and dataframe\n",
    "    \n",
    "    mean = np.mean(a[m:n]) # Calculates the mean for 3 floats \n",
    "    means.append(mean) # Save it to the list \n",
    "    \n",
    "    standard_dev = np.std(a[m:n]) # Calculates the sd for 3 floats\n",
    "    sds.append(standard_dev) # Save it to the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f987d12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot final validation accuracies with standard deviations\n",
    "\n",
    "plt.xlabel(\"Reg Factor\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracies with Standard Deviations\")\n",
    "\n",
    "regFactors = np.linspace(0.000001,0.001,5) # Same as regFactors\n",
    "plt.scatter(regFactors, means)\n",
    "\n",
    "plt.errorbar(regFactors, means, sds, linestyle='none', fmt='o', markersize=4, capsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3e5eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max validation accuracy:  0.9832000136375428\n"
     ]
    }
   ],
   "source": [
    "print(\"Max validation accuracy: \", np.max(df_2D['Test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2634e73",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">INSERT COMMENT TO ABOVE ACCURACY SCORES</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430da424",
   "metadata": {},
   "source": [
    "### 3.  Convolutional layers. (2p)\n",
    "\n",
    "##### 3(A)\n",
    "Design a model that makes use of at least one convolutional layer – how performant a model can\n",
    "you get? -- According to the MNIST database it should be possible reach to 99% accuracy on the\n",
    "validation data. If you choose to use any layers apart from convolutional layers and layers that you\n",
    "used in previous questions, you must describe what they do. If you do not reach 99% accuracy,\n",
    "report your best performance and explain your attempts and thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ac9e5",
   "metadata": {},
   "source": [
    "##### 3(B)\n",
    "Discuss the differences and potential benefits of using convolutional layers over fully connected\n",
    "ones for the particular application?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec599416",
   "metadata": {},
   "source": [
    "### 4. Auto-Encoders for denoising (3p)\n",
    "\n",
    "##### 4(A)\n",
    "The notebook implements a simple denoising deep autoencoder model. Explain what the model\n",
    "does: use the data-preparation and model definition code to explain how the goal of the model is\n",
    "achieved. Explain the role of the loss function? Draw a diagram of the model and include it in your\n",
    "report. Train the model with the settings given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def salt_and_pepper(input, noise_level=0.5):\n",
    "    \"\"\"\n",
    "    This applies salt and pepper noise to the input tensor - randomly setting bits to 1 or 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : tensor\n",
    "        The tensor to apply salt and pepper noise to.\n",
    "    noise_level : float\n",
    "        The amount of salt and pepper noise to add.\n",
    "    Returns\n",
    "    -------\n",
    "    tensor\n",
    "        Tensor with salt and pepper noise applied.\n",
    "    \"\"\"\n",
    "    # salt and pepper noise\n",
    "    a = np.random.binomial(size=input.shape, n=1, p=(1 - noise_level))\n",
    "    b = np.random.binomial(size=input.shape, n=1, p=0.5)\n",
    "    c = (a==0) * b\n",
    "    return input * a + c\n",
    "\n",
    "\n",
    "#data preparation\n",
    "flattened_x_train = x_train.reshape(-1,784)\n",
    "flattened_x_train_seasoned = salt_and_pepper(flattened_x_train, noise_level=0.4)\n",
    "\n",
    "flattened_x_test = x_test.reshape(-1,784)\n",
    "flattened_x_test_seasoneed = salt_and_pepper(flattened_x_test, noise_level=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 96  \n",
    "\n",
    "input_image = keras.Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_image)\n",
    "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_image, decoded)\n",
    "encoder_only = keras.Model(input_image, encoded)\n",
    "\n",
    "encoded_input = keras.Input(shape=(latent_dim,))\n",
    "decoder_layer = Sequential(autoencoder.layers[-2:])\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_info_AE = autoencoder.fit(flattened_x_train_seasoned, flattened_x_train,\n",
    "                epochs=32,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(flattened_x_test_seasoneed, flattened_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69c4d3",
   "metadata": {},
   "source": [
    "##### 4(B)\n",
    "Add increasing levels of noise to the test-set using the salt_and_pepper()-function (0 to 1).\n",
    "Use matplotlib to visualize a few examples (3-4) in the original, “seasoned” (noisy), and denoised\n",
    "versions (Hint: for visualization use imshow(), use the trained autoencoder to denoise the noisy\n",
    "digits). At what noise level does it become difficult to identify the digits for you? At what noise level\n",
    "does the denoising stop working?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fce27f",
   "metadata": {},
   "source": [
    "##### 4(C)\n",
    "Test whether denoising improves the classification with the best performing model you obtained\n",
    "in questions 2 or 3. Plot the true-positive rate as a function of noise-level for the seasoned and\n",
    "denoised datasets – assume that the correct classification is the most likely class-label. Discuss your\n",
    "results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeae1f3",
   "metadata": {},
   "source": [
    "##### 4(D)\n",
    "Explain how you can use the decoder part of the denoising auto-encoder to generate synthetic\n",
    "“hand-written” digits? – Describe the procedure and show examples in your report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
