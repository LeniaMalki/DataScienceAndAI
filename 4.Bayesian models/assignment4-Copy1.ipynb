{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAT405 Introduction to Data Science and AI\n",
    "# Assignment 4: Spam classification using Naïve Bayes\n",
    "\n",
    "Student name | Hours spent on the tasks\n",
    "------------ | -------------\n",
    "Lenia Malki | 10\n",
    "Maële Belmont | 10\n",
    "\n",
    "ask:\n",
    "- question 1: open 1 mail or all of them? store them in lists or dataframe? why can't open file number 2 in easy_ham and file number 4 in hard_ham? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Python modules need to be loaded to solve the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "There will be an overall grade for this assignment. To get a pass grade (grade 3), you need to pass \n",
    "items 1-3 below. To receive higher grades, finish items 4 and 5 as well.<br>\n",
    "In this assignment you will implement a Naïve Bayes classifier in Python that will classify emails into \n",
    "spam and non-spam (“ham”) classes. Your program should be able to train on a given set of spam \n",
    "and “ham” datasets.   You will work with the datasets available at https://spamassassin.apache.org/old/publiccorpus/. \n",
    "There are three types of files in this location: \n",
    "1. easy-ham: non-spam messages typically quite easy to differentiate from spam messages. \n",
    "2. hard-ham: non-spam messages more difficult to differentiate\n",
    "3. spam: spam messages\n",
    "\n",
    "Read the “readme.html” for a full description of the file contents. The .bz2-file can be unzipped using \n",
    "the linux command\n",
    "tar –xjvf file.bz2\n",
    "which will result in a directory named “file”, containing all email messages as separate files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Preprocessing: \n",
    "#### a. Note that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text. Further down (in the higher grade part), you will be asked to filter out the headers and footers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. We don’t want to train and test on the same data. Split the spam and the ham datasets in a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method which saves file paths of a given directory to a dataframe\n",
    "def getFilePaths(directory):\n",
    "    filepaths  = [os.path.join(directory, name) for name in os.listdir(directory)]\n",
    "    df = pd.DataFrame(filepaths)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method which extracts all messages of a dataframe into a new data frame\n",
    "def getFileContent(dataFrame):\n",
    "    messages = []\n",
    "    for i in range(len(dataFrame)):\n",
    "        filename = str(ham_train.iloc[i][0])\n",
    "        with open(filename) as f:\n",
    "            messages.append(f.read())\n",
    "    data = pd.DataFrame(messages)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike or None, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14632/3305915630.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mspam_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFilePaths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0me_ham_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFileContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_ham_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mh_ham_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFileContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_ham_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mspam_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFileContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14632/2928648758.py\u001b[0m in \u001b[0;36mgetFileContent\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Method which extracts all messages of a dataframe into a new data frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetFileContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFilePaths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14632/1483859220.py\u001b[0m in \u001b[0;36mgetFilePaths\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Method which saves file paths of a given directory to a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetFilePaths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfilepaths\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike or None, not DataFrame"
     ]
    }
   ],
   "source": [
    "#Assigns each dataset to each variable\n",
    "e_ham_files = getFilePaths('easy_ham')\n",
    "h_ham_files = getFilePaths('hard_ham') \n",
    "spam_files = getFilePaths('spam')\n",
    "\n",
    "e_ham_content = getFileContent(e_ham_files)\n",
    "h_ham_content = getFileContent(h_ham_files)\n",
    "spam_content = getFileContent(spam_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging ham data frames together as they are of the same type, keeping the amount of variables low\n",
    "ham_conent = pd.concat([e_ham_content, h_ham_content])\n",
    "\n",
    "# Split dataset into training set and test set (70-30)\n",
    "ham_train, ham_test = train_test_split(ham_conent, test_size=0.3, random_state=0)\n",
    "spam_train, spam_test = train_test_split(spam_content, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From fork-admin@xent.com  Mon Sep 23 23:01:14 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From fork-admin@xent.com  Sat Sep 21 15:19:01 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From fork-admin@xent.com  Mon Sep 30 19:59:00 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From rssfeeds@jmason.org  Wed Oct  2 11:43:41 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Return-Path: anthony@interlink.com.au\\nDeliver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>From fork-admin@xent.com  Sun Sep 22 21:57:43 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>From fork-admin@xent.com  Wed Sep 25 10:24:49 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>From razor-users-admin@lists.sourceforge.net  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>Return-Path: &lt;Online#3.20001.96-U3_zlwFfMd5UDd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>Return-Path: ticket_erp.xem7f9k1029828689438@s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1960 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     From fork-admin@xent.com  Mon Sep 23 23:01:14 ...\n",
       "1     From fork-admin@xent.com  Sat Sep 21 15:19:01 ...\n",
       "2     From fork-admin@xent.com  Mon Sep 30 19:59:00 ...\n",
       "3     From rssfeeds@jmason.org  Wed Oct  2 11:43:41 ...\n",
       "4     Return-Path: anthony@interlink.com.au\\nDeliver...\n",
       "...                                                 ...\n",
       "1955  From fork-admin@xent.com  Sun Sep 22 21:57:43 ...\n",
       "1956  From fork-admin@xent.com  Wed Sep 25 10:24:49 ...\n",
       "1957  From razor-users-admin@lists.sourceforge.net  ...\n",
       "1958  Return-Path: <Online#3.20001.96-U3_zlwFfMd5UDd...\n",
       "1959  Return-Path: ticket_erp.xem7f9k1029828689438@s...\n",
       "\n",
       "[1960 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hamFiles = readFiles(ham_train)\n",
    "display(hamFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Write a Python program that:\n",
    "#### a. Uses four datasets (hamtrain, spamtrain, hamtest, and spamtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Using a Naïve Bayes classifier (e.g. Sklearn), classifies the test sets and reports the  percentage of ham and spam test sets that were classified correctly. You can use CountVectorizer to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in SKlearn (Document is available here). Test two of these classifiers: 1. Multinomial Naive Bayes and 2. Bernoulli Naive Bayes that are well suited for this problem. For the case of Bernoulli Naive Bayes you should use the parameter binarize to make the features binary. Discuss the differences between these two classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Run your program on\n",
    "#### i. Spam versus easy-ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Spam versus hard-ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - To avoid classification based on common and uninformative words it is common to filter these out. \n",
    "#### a. Argue why this may be useful. Try finding the words that are too common/uncommon in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Use the parameters in Sklearn’s CountVectorizer to filter out these words. Run the updated program on your data and record how the results differ from 3. You have two options to do this in Sklearn: either using the words found in part (a) or letting Sklearn do it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Filter out the headers and the footers of the emails before you run on them. The format may vary somewhat between emails, which can make this a bit tricky, so perfect filtering is not required. Run your program again and answer the following questions: \n",
    "#### a. Does the result improve from 3 and 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. The split of the data set into a training set and a test set can lead to very skewed results. Why is this, and do you have suggestions on remedies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. What do you expect would happen if your training set were mostly spam messages while your test set were mostly ham messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
